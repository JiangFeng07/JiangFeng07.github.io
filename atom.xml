<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>江峰的技术博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://JiangFeng07.github.com/"/>
  <updated>2017-03-24T10:33:27.000Z</updated>
  <id>http://JiangFeng07.github.com/</id>
  
  <author>
    <name>Jiang Feng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>朴素贝叶斯算法</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/朴素贝叶斯/</id>
    <published>2017-03-24T10:28:43.000Z</published>
    <updated>2017-03-24T10:33:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>贝叶斯定理想必大家很早就已经了解，朴素贝叶斯算法就是基于贝叶斯定理提出的一种监督机器学习算法。为什么叫“朴素”了？那是因为朴素贝叶斯分类器基于一个简单的假定：给定目标值时属性之间相互条件独立。给定类变量 y (这里一个样本仅属于一类) 和一个相互独立的特征向量 $x_1$ 到 $x_n$，贝叶斯定理可得到如下关系：</p>
<script type="math/tex; mode=display">P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)}
                                 {P(x_1, \dots, x_n)}</script><p>使用朴素（naive）的假设：每个特征之间相互独立：</p>
<script type="math/tex; mode=display">P(x_i | y, x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n) = P(x_i | y)</script><p>对于所有的$i$,这个关系可以简化为：</p>
<script type="math/tex; mode=display">P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)}
                                 {P(x_1, \dots, x_n)}</script><p>由于${P(x_1, \dots, x_n)}$的值当给定的特征不变式是固定的，所以可以得到以下分类规则：</p>
<script type="math/tex; mode=display">P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y)</script><p>并且我们可以使用最大后验概率（MAP）估计来估计$P(y) $ ,$P(x_i \mid y)$;<br>不同的朴素贝叶斯分类器的不同之处在于：它们对$P(x_i \mid y)$的分布的认识和假设不同。目前常用的有高斯模型、多项式模型和伯努利模型这三种模型。本文主要介绍高斯模型以及对应的 python 实现。</p>
<h2 id="朴素贝叶斯算法-高斯模型"><a href="#朴素贝叶斯算法-高斯模型" class="headerlink" title="朴素贝叶斯算法 高斯模型"></a>朴素贝叶斯算法 高斯模型</h2><p>高斯模型假设这些一个特征的所有属于某个类别的观测值符合高斯分布:</p>
<script type="math/tex; mode=display">P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)</script><h2 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line"># -*- coding: utf-8 -*-</div><div class="line"></div><div class="line">import random</div><div class="line">import math</div><div class="line"></div><div class="line"></div><div class="line"># 根据文件路径加载数据</div><div class="line">def load_data(file_name):</div><div class="line">    file = open(file_name)</div><div class="line">    data = []</div><div class="line">    for line in file.readlines():</div><div class="line">        tmpline = line.split(&apos; &apos;)</div><div class="line">        tmp = []</div><div class="line">        for x in tmpline:</div><div class="line">            tmp.append(float(x))</div><div class="line">        data.append(tmp)</div><div class="line">    return data</div><div class="line"></div><div class="line"></div><div class="line"># 数据分为训练数据 train_set 和测试数据 test_set</div><div class="line">def split_data(data, split_ratio):</div><div class="line">    train_size = int(len(data) * split_ratio)</div><div class="line">    train_set = []</div><div class="line">    test_set = list(data)</div><div class="line">    while len(train_set) &lt; train_size:</div><div class="line">        index = random.randrange(len(test_set))</div><div class="line">        train_set.append(test_set.pop(index))</div><div class="line">    return [train_set, test_set]</div><div class="line"></div><div class="line"></div><div class="line"># 根据结果分类</div><div class="line">def separate_by_class(data):</div><div class="line">    y = &#123;&#125;</div><div class="line">    for i in range(len(data)):</div><div class="line">        vector = data[i]</div><div class="line">        if vector[-1] not in y:</div><div class="line">            y[vector[-1]] = []</div><div class="line">        y[vector[-1]].append(vector)</div><div class="line">    return y</div><div class="line"></div><div class="line"></div><div class="line"># 计算平均值</div><div class="line">def average(numbers):</div><div class="line">    return sum(numbers) / float(len(numbers))</div><div class="line"></div><div class="line"></div><div class="line"># 计算样本方差</div><div class="line">def stdev(numbers):</div><div class="line">    avg = average(numbers)</div><div class="line">    variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)</div><div class="line">    return math.sqrt(variance)</div><div class="line"></div><div class="line"></div><div class="line"># 计算每个属性的平均值和样本方差</div><div class="line">def summarize(data):</div><div class="line">    summaries = [(average(attribute), stdev(attribute)) for attribute in zip(*data)]</div><div class="line">    del summaries[-1]</div><div class="line">    return summaries</div><div class="line"></div><div class="line"></div><div class="line">def summaries_by_class(data):</div><div class="line">    y = separate_by_class(data)</div><div class="line">    summaries = &#123;&#125;</div><div class="line">    for classValue, instances in y.items():</div><div class="line">        summaries[classValue] = summarize(instances)</div><div class="line">    return summaries</div><div class="line"></div><div class="line"></div><div class="line"># 计算高斯分布</div><div class="line">def calculate_Probability(x, avg, stdev):</div><div class="line">    exponent = math.exp((-1) * (math.pow(x - avg, 2) / (2 * math.pow(stdev, 2))))</div><div class="line">    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent</div><div class="line"></div><div class="line"></div><div class="line"># 计算输入向量的贝叶斯概率</div><div class="line">def calculateClassProbabilities(summaries, inputVector):</div><div class="line">    probabilities = &#123;&#125;</div><div class="line">    for classValue, classSummaries in summaries.items():</div><div class="line">        probabilities[classValue] = 1</div><div class="line">        for i in range(len(classSummaries)):</div><div class="line">            avg, stdev = classSummaries[i]</div><div class="line">            x = inputVector[i]</div><div class="line">            probabilities[classValue] *= calculate_Probability(x, avg, stdev)</div><div class="line">    return probabilities</div><div class="line"></div><div class="line"></div><div class="line"># 找到最大的值</div><div class="line">def predict(summaries, inputVector):</div><div class="line">    probabilities = calculateClassProbabilities(summaries, inputVector)</div><div class="line">    bestLabel, bestProb = None, -1</div><div class="line">    for classValue, probability in probabilities.items():</div><div class="line">        if bestLabel is None or probability &gt; bestProb:</div><div class="line">            bestProb = probability</div><div class="line">            bestLabel = classValue</div><div class="line">    return bestLabel</div><div class="line"></div><div class="line"></div><div class="line">def getPredictions(summaries, testSet):</div><div class="line">    predictions = []</div><div class="line">    for i in range(len(testSet)):</div><div class="line">        result = predict(summaries, testSet[i])</div><div class="line">        predictions.append(result)</div><div class="line">    return predictions</div><div class="line"></div><div class="line"></div><div class="line"># 计算预测正确率</div><div class="line">def getAccuracy(testSet, predictions):</div><div class="line">    correct = 0</div><div class="line">    for i in range(len(testSet)):</div><div class="line">        if testSet[i][-1] == predictions[i]:</div><div class="line">            correct += 1</div><div class="line">    return (correct / float(len(testSet))) * 100.0</div><div class="line"></div><div class="line"></div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    data = load_data(&quot;/tmp/pima-indians-diabetes.txt&quot;)</div><div class="line">    trainSet, testSet = split_data(data, 0.8)</div><div class="line">    summaries = summaries_by_class(trainSet)</div><div class="line">    print(</div><div class="line">        &apos;split &#123;0&#125; rows data into &#123;1&#125; rows trainData and &#123;2&#125; rows testData&apos;.format(len(data), len(trainSet), len(testSet)))</div><div class="line">    predictions = getPredictions(summaries, testSet)</div><div class="line">    accuracy = getAccuracy(testSet, predictions)</div><div class="line">    print(&apos;Accuracy:&#123;0&#125;%&apos;.format(accuracy))</div></pre></td></tr></table></figure>
<p>本实验进行了10次测试，得到的平均正确率为74.42%。</p>
<ul>
<li>参考资料：<ul>
<li><a href="http://sklearn.lzjqsdd.com/modules/naive_bayes.html#gaussian-naive-bayes" target="_blank" rel="external">朴素贝叶斯</a></li>
<li><a href="http://python.jobbole.com/81019/" target="_blank" rel="external">机器学习之用Python从零实现贝叶斯分类器</a></li>
</ul>
</li>
<li>数据集<ul>
<li><a href="http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data" target="_blank" rel="external">数据集地址</a></li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;贝叶斯定理想必大家很早就已经了解，朴素贝叶斯算法就是基于贝叶斯定理提出的一种监督机器学习算法。为什么叫“朴素”了？那是因为朴素贝叶斯分类器基于一个简单的假定：给定目标值时属性之间相互条件独立。给定类变量 y (这里一个样本仅属于一类) 和一个相互独立的特征向量 $x_1$ 
    
    </summary>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降法</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/梯度下降法/</id>
    <published>2017-03-24T10:09:15.000Z</published>
    <updated>2017-03-24T10:24:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降法，又叫最速下降法，是一种最优化算法。它用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。<br>梯度下降法的计算过程就是沿着梯度下降的方向求解极小值。（亦可以沿着梯度上升的方向求解极大值）。它的迭代公式为:</p>
<script type="math/tex; mode=display">a_{k+1}=a_{k}+\gamma_ks^{-(k)}(式1-1)</script><p>其中，$s^{-(k)}$代表的是梯度的负方向，$\gamma_k$表示梯度方向上的搜索步长。梯度方向可以通过求导得到，步长的设定则比较麻烦，太大的容易发散，找不到极小值的点，太小的话则收敛的速度比较慢。</p>
<ul>
<li>示例<br>现有函数$f(x)=x^4-3x^3+2$,则利用梯度下降方法解题的步骤如下：<br>1.求梯度，即对函数求导，$f(x)=4x^3-9x^2$；<br>2.根据式1-1，向梯度相反的方向移动 $x$；<br>3.循环迭代步骤2，直到x的值变化到使得$f(x)$在两次迭代之间的差值足够小，比如0.00000001，也就是说，直到两次迭代计算出来的$f(x)$基本没有变化，则说明此时$f(x)$已经达到局部最小值了。<br>4.此时，输出 $x$，此时求得的 $x$ 就是使得$f(x)$取得最小值的 x 的值。</li>
<li>代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#python 代码</span></div><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"></div><div class="line">x_old = <span class="number">0</span></div><div class="line">x_new = <span class="number">6</span></div><div class="line">gamma = <span class="number">0.01</span></div><div class="line">precision = <span class="number">0.00000001</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># x = Symbol("x")</span></div><div class="line"><span class="comment"># f = (x ** 4) - (3 * (x ** 3)) + 2</span></div><div class="line"></div><div class="line"><span class="comment">#梯度下降算法</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">df</span><span class="params">(x)</span>:</span></div><div class="line">    y = <span class="number">4</span> * x**<span class="number">3</span> - <span class="number">9</span> * x**<span class="number">2</span></div><div class="line">    <span class="keyword">return</span> y</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">while</span> abs(x_new - x_old) &gt; precision:</div><div class="line">    x_old = x_new</div><div class="line">    x_new += -gamma * df(x_old)</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"The local minimum occurs at"</span>, x_new//The local minimum occurs at <span class="number">2.24999996819</span></div></pre></td></tr></table></figure>
<p>利用数学知识可以求得函数$f(x)=x^4-3x^3+2$的极小值在$\frac{9}{4}$取得，即2.25，代码求得的结果是2.24999996819，已经满足小于0.00000001的条件，代码有效。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;梯度下降法，又叫最速下降法，是一种最优化算法。它用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。&lt;br&gt;梯度下降法的计算过程就是沿着梯度下降的方向求解极小值。（亦可以沿着梯度上升的方向求解极大值）。它的迭代公式为:&lt;/p&gt;
&lt;script type=&quot;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ansj分词简单案例</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/ansj%E5%88%86%E8%AF%8D%E7%AE%80%E5%8D%95%E6%A1%88%E4%BE%8B/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/ansj分词简单案例/</id>
    <published>2017-03-24T08:35:52.000Z</published>
    <updated>2017-03-24T09:42:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>如今，自然语言处理技术越来越成熟，越来越得到大家关注。许多互联网公司，如京东，阿里，新美大等互联网公司都有大量的文本评论数据，如何从这些文本中挖掘出有效的信息成为关键，这就需要应用自然语言处理技术，而对文本分词是自然语言处理的第一步，很关键。分词工具有很多<a href="http://ictclas.nlpir.org/" target="_blank" rel="external">NLPIR</a>、<a href="http://code.google.com/p/ik-analyzer/" target="_blank" rel="external">IKAnalyzer</a>、<a href="https://www.baidu.com/link?url=Bv6PmRepvb8vA06WGOUleDBM6Yd-fvmNnTkGOZGDRXrmaMTU2DVEJ7Mt2HAPrZi-&amp;wd=&amp;eqid=b847872c0002fb5400000004582d599d" target="_blank" rel="external">stanford nlp</a>等等，本篇博文将介绍我所使用的分词工具 <a href="https://github.com/NLPchina/ansj_seg" target="_blank" rel="external">Ansj</a> 的使用。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul>
<li><p>下载 jar</p>
<p>访问<a href="http://maven.nlpcn.org/org/ansj/" target="_blank" rel="external">http://maven.nlpcn.org/org/ansj/ </a>下载ansj-seg，倒入自己的 IDE，就可以了。如果你使用 maven，可以添加以下依赖：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;!-- 增加新的maven源 --&gt;</div><div class="line">&lt;repositories&gt;</div><div class="line">    &lt;repository&gt;</div><div class="line">        &lt;id&gt;mvn-repo&lt;/id&gt;</div><div class="line">        &lt;url&gt;http://maven.nlpcn.org/&lt;/url&gt;</div><div class="line">    &lt;/repository&gt;</div><div class="line">&lt;/repositories&gt;</div><div class="line"></div><div class="line"></div><div class="line">&lt;dependencies&gt;</div><div class="line">    ....</div><div class="line"></div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.ansj&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;ansj_seg&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;5.0.1&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    ....</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h2 id="示例演示"><a href="#示例演示" class="headerlink" title="示例演示"></a>示例演示</h2><p>先来看一个简单的的 demo 演示。</p>
<ul>
<li>Demo</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">import org.ansj.splitWord.analysis.ToAnalysis;</div><div class="line">import org.junit.Test;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Created by lionel on 16/11/17.</div><div class="line"> */</div><div class="line">public class AnsjTest &#123;</div><div class="line">    @Test</div><div class="line">    public void test()&#123;</div><div class="line">        String text=&quot;中新网11月17日电 据外媒报道，日本首相安倍晋三称，有机会在唐纳德•特朗普获得美国大选胜利后，成为第一个与他会晤的外国领导人是“莫大的荣幸”，并表示希望在他们之间建立信任关系。报道称，特朗普与安倍或将于当地时间17日傍晚在纽约会谈。&quot;;</div><div class="line">        System.out.println(ToAnalysis.parse(text));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>分词结果</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">中/f,新/a,网/n,11月/m,17日/m,电/n, ,据/p,外/f,媒/ng,报道/v,，/w,日本/ns,首相/n,安倍/nr,晋/j,三/m,称/v,，</div><div class="line">/w,有/v,机会/n,在/p,唐纳德/nr,•,特朗普/nr,获得/v,美国/ns,大选/vn,胜利/vn,后/f,，/w,成为/v,第一个/m,与/p,</div><div class="line">他/r,会晤/v,的/uj,外国/n,领导人/n,是/v,“/w,莫大/b,的/uj,荣幸/a,”/w,，/w,并/c,表示/v,希望/v,在/p,他们/r,</div><div class="line">之间/f,建立/v,信任/v,关系/n,。/w,报道/v,称/v,，/w,特朗普/nr,与/p,安倍/nr,或/c,将/d,于/p,当地/s,时间/n,</div><div class="line">17日/m,傍晚/t,在/p,纽约/ns,会谈/v,。/w</div></pre></td></tr></table></figure>
<p> 可以发现，文本已经分好词了，但是有些分词就不是很满意，如“中新网”就是一个网站名，应该就是一个词，又比如说安倍晋三是一个人名，应该就是一个词。要想解决这个问题就要加入自己的词库。</p>
<ul>
<li>自定义词库<br>现有以下词库：</li>
</ul>
<p>名字词库(name.dic)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">李连杰</div><div class="line">刘德华</div><div class="line">安倍晋三</div><div class="line">唐纳德.特兰普</div></pre></td></tr></table></figure></p>
<p>媒体词库(media.dic)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">中新网</div><div class="line">新华网</div></pre></td></tr></table></figure>
<p>以上两个词库我直接放在 <font color="ff0000">resources 文件夹</font>下。<br>通过UserDefineLibrary类中的静态方法 insertWord()来加载自己的词库。</p>
<ul>
<li>示例代码</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">import org.ansj.domain.Term;</div><div class="line">import org.ansj.library.UserDefineLibrary;</div><div class="line">import org.ansj.splitWord.analysis.ToAnalysis;</div><div class="line"></div><div class="line">import java.io.BufferedReader;</div><div class="line">import java.io.InputStream;</div><div class="line">import java.io.InputStreamReader;</div><div class="line">import java.util.List;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Created by lionel on 16/11/17.</div><div class="line"> */</div><div class="line">public class TextSegment &#123;</div><div class="line">    static &#123;</div><div class="line">        loadDictionary(&quot;/media.dic&quot;, &quot;media&quot;);</div><div class="line">        loadDictionary(&quot;/name.dic&quot;, &quot;name&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     *  从本地文件加载词库，并打上对应的标签，名字词库对应的词性是 name；媒体词库对应的词性是 media</div><div class="line">     *</div><div class="line">     * @param dic    本地词库路径</div><div class="line">     * @param speech 词性</div><div class="line">     */</div><div class="line">    public static void loadDictionary(String dic, String speech) &#123;</div><div class="line">        try &#123;</div><div class="line">            InputStream is = TextSegment.class.getResourceAsStream(dic);</div><div class="line">            BufferedReader reader = new BufferedReader(new InputStreamReader(is));</div><div class="line">            String line;</div><div class="line">            while ((line = reader.readLine()) != null) &#123;</div><div class="line">                String token = line.replaceAll(&quot;[\\r\\n]&quot;, &quot;&quot;).trim();</div><div class="line">                UserDefineLibrary.insertWord(token, speech, 1000);</div><div class="line">            &#125;</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * 实现分词</div><div class="line">     *</div><div class="line">     * @param text 文本</div><div class="line">     * @return 分词后的文本</div><div class="line">     */</div><div class="line">    public static List&lt;Term&gt; parse(String text) &#123;</div><div class="line">        if (text == null || text.length() == 0) &#123;</div><div class="line">            return null;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        return ToAnalysis.parse(text);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>分词结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">中新网/media,11月/m,17日/m,电/n, ,据/p,外/f,媒/ng,报道/v,，/w,日本/ns,首相/n,安倍晋三/name,称/v,，</div><div class="line">/w,有/v,机会/n,在/p,唐纳德•特朗普/name,获得/v,美国/ns,大选/vn,胜利/vn,后/f,，/w,成为/v,第一个/m,</div><div class="line">与/p,他/r,会晤/v,的/uj,外国/n,领导人/n,是/v,“/w,莫大/b,的/uj,荣幸/a,”/w,，/w,并/c,表示/v,希望/v,</div><div class="line">在/p,他们/r,之间/f,建立/v,信任/v,关系/n,。/w,报道/v,称/v,，/w,特朗普/nr,与/p,安倍/nr,或/c,将/d,</div><div class="line">于/p,当地/s,时间/n,17日/m,傍晚/t,在/p,纽约/ns,会谈/v,。/w</div></pre></td></tr></table></figure>
<p>从两次的分词结果比较结果可以看出，我们的词库已经起到了作用，对应的姓名和媒体都已经是单独的一个词了，而且词性也是自定义的词性。如，中新网/media，唐纳德•特朗普/name等等。这样就可以根据词性获取需要的信息了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如今，自然语言处理技术越来越成熟，越来越得到大家关注。许多互联网公司，如京东，阿里，新美大等互联网公司都有大量的文本评论数据，如何从这些文本中挖掘出有效的信息成为关键，这就需要应用自然语言处理技术，而对文本分词是自然语言处理的第一步，很关键。分词工具有很多&lt;a href=&quot;
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>mysql 分页查询优化</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/Mysql-%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/Mysql-分页查询优化/</id>
    <published>2017-03-21T11:35:22.000Z</published>
    <updated>2017-03-24T10:31:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>分页查询在 mysql 中常遇到，如以下语句 :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName limit 100,20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要0.03 sec。用时很短。<br>但是随着偏移量的增加，查询时间也随之增加。如下代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName limit 10000000,20</div></pre></td></tr></table></figure></p>
<p>用时大约需要32.43 sec，这个时间是不是就有点长了了？可以优化吗？答案是可以的。那么，该怎样优化？</p>
<p><strong>优化方法1</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName order by id limit 10000000,20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要17.71 sec，还是有点长。</p>
<p><strong>优化方法2</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName where id &gt;= (select id from TableName order by id limit 10000000,1) limit 20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要4.01 sec。</p>
<p><strong>优化方法3</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName a, (select id from TableName where status=1 order by id limit 10000000,10) b where a.id=b.id</div></pre></td></tr></table></figure></p>
<p>用时大约需要4.43sec。</p>
<p><strong>优化方法4</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName as a inner join (select id from TableName order by id limit 10000000,20) as b on a.id=b.id order by a.id;</div></pre></td></tr></table></figure></p>
<p>用时大约需要3.98sec。</p>
<p>可见优化方法2、优化方法3 和 优化方法4 运行时间差不多，相比于32.43 sec，效率提高八倍左右。</p>
<p>注：sql 语句中的 TableName指代的工作中一个有40000000多万记录的表。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分页查询在 mysql 中常遇到，如以下语句 :&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td cl
    
    </summary>
    
    
      <category term="Mysql" scheme="http://JiangFeng07.github.com/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>doc2vct算法实现</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/doc2vct%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/doc2vct算法实现/</id>
    <published>2017-03-21T10:03:56.000Z</published>
    <updated>2017-03-21T10:05:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章主要是实现Python 自然语言处理包 gensim 中用于长文本向量建模的 doc2vec算法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python3</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> multiprocessing</div><div class="line"><span class="keyword">import</span> os.path</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> utils</div><div class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> TaggedDocument, Doc2Vec</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDocs</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename)</span>:</span></div><div class="line">        self.filename = filename</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> open(self.filename, <span class="string">'rb'</span>):</div><div class="line">                pieces = utils.to_unicode(line).split()</div><div class="line">                tag = pieces[<span class="number">0</span>]</div><div class="line">                words = pieces[<span class="number">1</span>].split(<span class="string">','</span>)</div><div class="line">                <span class="keyword">yield</span> TaggedDocument(words, [tag])</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            logging.info(<span class="string">'e'</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    program = os.path.basename(sys.argv[<span class="number">0</span>])</div><div class="line">    logger = logging.getLogger(program)</div><div class="line"></div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s: %(levelname)s: %(message)s'</span>)</div><div class="line">    logging.root.setLevel(level=logging.INFO)</div><div class="line">    logger.info(<span class="string">"running %s"</span> % <span class="string">' '</span>.join(sys.argv))</div><div class="line"></div><div class="line">    <span class="comment"># check and process input arguments</span></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">4</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    inp, outp1, outp2 = sys.argv[<span class="number">1</span>:<span class="number">4</span>]</div><div class="line"></div><div class="line">    documents = MyDocs(inp)</div><div class="line">    <span class="comment">#建立模型</span></div><div class="line">    model = Doc2Vec(documents, size=<span class="number">200</span>, window=<span class="number">5</span>, min_count=<span class="number">20</span>, workers=multiprocessing.cpu_count())</div><div class="line"></div><div class="line">    <span class="comment"># trim unneeded model memory = use(much) less RAM</span></div><div class="line">    <span class="comment"># model.init_sims(replace=True)</span></div><div class="line">    <span class="comment">#保存模型</span></div><div class="line">    model.save(outp1)</div><div class="line">    model.save_word2vec_format(outp2, binary=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>说明一下：在MyDocs这个类中，我自定义了一个逐步读取文件的方法，因为在试验中我们发现，一个4个G 左右大小的文件在一个服务器内存为64G 的服务器上是不够用的，内存消耗非常之快，所以就看了一下源码中TaggedLineDocument和LineSentence这个类的源码，发现使用 yield这个关键字能很好的解决这个问题，便有了MyDocs类，实验结果表明，效果大大提高。有兴趣的同学可以看看 yield的用法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试模型</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Doc2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="comment"># check and process input arguments</span></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    file, word = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line"></div><div class="line">    <span class="comment">#加载模型</span></div><div class="line">    docvecs = Doc2Vec.load(file).docvecs</div><div class="line">    print(docvecs.most_similar(word))</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章主要是实现Python 自然语言处理包 gensim 中用于长文本向量建模的 doc2vec算法。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>word2vct算法实现</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/word2vct%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/word2vct算法实现/</id>
    <published>2017-03-21T09:50:51.000Z</published>
    <updated>2017-03-21T10:03:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章主要是实现Python 自然语言处理包 gensim 中用于词向量建模的 word2vec算法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    outputFile1, outputFile2 = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line"></div><div class="line">    sentences = [</div><div class="line">        <span class="string">"I think that most of us know by now that water is essential to our survival We’ve probably also all heard doctors say that drinking roughly eight glasses a day is ideal"</span>,</div><div class="line">        <span class="string">"yoyoyo you go home now to sleep"</span>]</div><div class="line"></div><div class="line">    vocab = [s.encode(<span class="string">'utf-8'</span>).decode().split() <span class="keyword">for</span> s <span class="keyword">in</span> sentences]</div><div class="line">    <span class="comment">#建立模型</span></div><div class="line">    model = Word2Vec(sentences, size=<span class="number">100</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, workers=<span class="number">4</span>)</div><div class="line">    <span class="comment">#保存模型</span></div><div class="line">    model.save(outputFile1)</div><div class="line">    model.save_word2vec_format(outputFile2, binary=<span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试模型</span></div><div class="line"><span class="comment"># encoding='utf-8'</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    file, word = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line">    <span class="comment">#从磁盘文件 file 加载模型</span></div><div class="line">    model = Word2Vec.load_word2vec_format(file, binary=<span class="keyword">False</span>)</div><div class="line">    print(model.most_similar(word))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章主要是实现Python 自然语言处理包 gensim 中用于词向量建模的 word2vec算法。&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;l
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow 安装和卸载</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/tensorflow-%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/tensorflow-安装和卸载/</id>
    <published>2017-03-21T09:07:31.000Z</published>
    <updated>2017-03-21T11:00:54.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于-virtualenv-安装"><a href="#基于-virtualenv-安装" class="headerlink" title="基于 virtualenv 安装"></a>基于 virtualenv 安装</h2><p>安装步骤如下：</p>
<ol>
<li>打开终端（a shell）;</li>
<li><p>安装 pip（如果之前没有安装的话） 和 virtualenv :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo easy_install pip</div><div class="line">$ sudo pip install --upgrade virtualenv</div></pre></td></tr></table></figure>
</li>
<li><p>建立一个新的 virtualenv 环境 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ virtualenv --system-site-packages ~/tensorflow</div></pre></td></tr></table></figure>
</li>
<li><p>激活 virtualenv :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ cd ~/tensorflow</div><div class="line">$ source bin/activate # 如果使用 bash, sh, ksh, 或者 zsh</div><div class="line">$ source bin/activate.csh # 如果使用 csh 或者 tcsh</div><div class="line">终端发生变化:</div><div class="line">(tensorflow)$</div></pre></td></tr></table></figure>
</li>
<li><p>安装 tensorflow :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install --upgrade tensorflow # for python 2.7</div><div class="line">pip3 install --upgrade tensorflow # for python 3.n</div></pre></td></tr></table></figure>
</li>
<li><p>测试是否安装成功 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(tensorflow) $ bin python</div><div class="line">Python 3.5.2 (default, Jul 28 2016, 21:28:00)</div><div class="line">[GCC 4.2.1 Compatible Apple LLVM 7.3.0 (clang-703.0.31)] on darwin</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)</div><div class="line">&gt;&gt;&gt; sess = tf.Session()</div><div class="line">&gt;&gt;&gt; print(sess.run(hello))</div><div class="line">b&apos;Hello, TensorFlow!&apos; # 安装成功</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="tensorflow-卸载"><a href="#tensorflow-卸载" class="headerlink" title="tensorflow 卸载"></a>tensorflow 卸载</h2><ol>
<li>执行卸载很简单，直接删除目录即可：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rm -r ~/tensorflow</div></pre></td></tr></table></figure></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基于-virtualenv-安装&quot;&gt;&lt;a href=&quot;#基于-virtualenv-安装&quot; class=&quot;headerlink&quot; title=&quot;基于 virtualenv 安装&quot;&gt;&lt;/a&gt;基于 virtualenv 安装&lt;/h2&gt;&lt;p&gt;安装步骤如下：&lt;/p&gt;
&lt;o
    
    </summary>
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/hello-world/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/hello-world/</id>
    <published>2017-03-21T08:56:25.000Z</published>
    <updated>2017-03-21T08:56:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
</feed>
