<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>江峰的技术博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://JiangFeng07.github.com/"/>
  <updated>2017-03-24T10:13:09.000Z</updated>
  <id>http://JiangFeng07.github.com/</id>
  
  <author>
    <name>Jiang Feng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>梯度下降法</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/梯度下降法/</id>
    <published>2017-03-24T10:09:15.000Z</published>
    <updated>2017-03-24T10:13:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降法，又叫最速下降法，是一种最优化算法。它用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。<br>梯度下降法的计算过程就是沿着梯度下降的方向求解极小值。（亦可以沿着梯度上升的方向求解极大值）。它的迭代公式为:</p>
<script type="math/tex; mode=display">a_{k+1}=a_{k}+\gamma_ks^{-(k)}(式1-1)</script><p>其中，$s^{-(k)}$代表的是梯度的负方向，$\gamma_k$表示梯度方向上的搜索步长。梯度方向可以通过求导得到，步长的设定则比较麻烦，太大的容易发散，找不到极小值的点，太小的话则收敛的速度比较慢。</p>
<ul>
<li>示例<br>现有函数$f(x)=x^4-3x^3+2$,则利用梯度下降方法解题的步骤如下：<br>1.求梯度，即对函数求导，$f^,(x)=4x^3-9x^2$；<br>2.根据式1-1，向梯度相反的方向移动 $x$；<br>3.循环迭代步骤2，直到x的值变化到使得$f(x)$在两次迭代之间的差值足够小，比如0.00000001，也就是说，直到两次迭代计算出来的$f(x)$基本没有变化，则说明此时$f(x)$已经达到局部最小值了。<br>4.此时，输出 $x$，此时求得的 $x$ 就是使得$f(x)$取得最小值的 x 的值。</li>
<li>代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#python 代码</span></div><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"></div><div class="line">x_old = <span class="number">0</span></div><div class="line">x_new = <span class="number">6</span></div><div class="line">gamma = <span class="number">0.01</span></div><div class="line">precision = <span class="number">0.00000001</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># x = Symbol("x")</span></div><div class="line"><span class="comment"># f = (x ** 4) - (3 * (x ** 3)) + 2</span></div><div class="line"></div><div class="line"><span class="comment">#梯度下降算法</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">df</span><span class="params">(x)</span>:</span></div><div class="line">    y = <span class="number">4</span> * x**<span class="number">3</span> - <span class="number">9</span> * x**<span class="number">2</span></div><div class="line">    <span class="keyword">return</span> y</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">while</span> abs(x_new - x_old) &gt; precision:</div><div class="line">    x_old = x_new</div><div class="line">    x_new += -gamma * df(x_old)</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"The local minimum occurs at"</span>, x_new//The local minimum occurs at <span class="number">2.24999996819</span></div></pre></td></tr></table></figure>
<p>利用数学知识可以求得函数$f(x)=x^4-3x^3+2$的极小值在$\frac{9}{4}$取得，即2.25，代码求得的结果是2.24999996819，已经满足小于0.00000001的条件，代码有效。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;梯度下降法，又叫最速下降法，是一种最优化算法。它用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。&lt;br&gt;梯度下降法的计算过程就是沿着梯度下降的方向求解极小值。（亦可以沿着梯度上升的方向求解极大值）。它的迭代公式为:&lt;/p&gt;
&lt;script type=&quot;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ansj分词简单案例</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/ansj%E5%88%86%E8%AF%8D%E7%AE%80%E5%8D%95%E6%A1%88%E4%BE%8B/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/ansj分词简单案例/</id>
    <published>2017-03-24T08:35:52.000Z</published>
    <updated>2017-03-24T09:42:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>如今，自然语言处理技术越来越成熟，越来越得到大家关注。许多互联网公司，如京东，阿里，新美大等互联网公司都有大量的文本评论数据，如何从这些文本中挖掘出有效的信息成为关键，这就需要应用自然语言处理技术，而对文本分词是自然语言处理的第一步，很关键。分词工具有很多<a href="http://ictclas.nlpir.org/" target="_blank" rel="external">NLPIR</a>、<a href="http://code.google.com/p/ik-analyzer/" target="_blank" rel="external">IKAnalyzer</a>、<a href="https://www.baidu.com/link?url=Bv6PmRepvb8vA06WGOUleDBM6Yd-fvmNnTkGOZGDRXrmaMTU2DVEJ7Mt2HAPrZi-&amp;wd=&amp;eqid=b847872c0002fb5400000004582d599d" target="_blank" rel="external">stanford nlp</a>等等，本篇博文将介绍我所使用的分词工具 <a href="https://github.com/NLPchina/ansj_seg" target="_blank" rel="external">Ansj</a> 的使用。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul>
<li><p>下载 jar</p>
<p>访问<a href="http://maven.nlpcn.org/org/ansj/" target="_blank" rel="external">http://maven.nlpcn.org/org/ansj/ </a>下载ansj-seg，倒入自己的 IDE，就可以了。如果你使用 maven，可以添加以下依赖：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;!-- 增加新的maven源 --&gt;</div><div class="line">&lt;repositories&gt;</div><div class="line">    &lt;repository&gt;</div><div class="line">        &lt;id&gt;mvn-repo&lt;/id&gt;</div><div class="line">        &lt;url&gt;http://maven.nlpcn.org/&lt;/url&gt;</div><div class="line">    &lt;/repository&gt;</div><div class="line">&lt;/repositories&gt;</div><div class="line"></div><div class="line"></div><div class="line">&lt;dependencies&gt;</div><div class="line">    ....</div><div class="line"></div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.ansj&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;ansj_seg&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;5.0.1&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    ....</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h2 id="示例演示"><a href="#示例演示" class="headerlink" title="示例演示"></a>示例演示</h2><p>先来看一个简单的的 demo 演示。</p>
<ul>
<li>Demo</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">import org.ansj.splitWord.analysis.ToAnalysis;</div><div class="line">import org.junit.Test;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Created by lionel on 16/11/17.</div><div class="line"> */</div><div class="line">public class AnsjTest &#123;</div><div class="line">    @Test</div><div class="line">    public void test()&#123;</div><div class="line">        String text=&quot;中新网11月17日电 据外媒报道，日本首相安倍晋三称，有机会在唐纳德•特朗普获得美国大选胜利后，成为第一个与他会晤的外国领导人是“莫大的荣幸”，并表示希望在他们之间建立信任关系。报道称，特朗普与安倍或将于当地时间17日傍晚在纽约会谈。&quot;;</div><div class="line">        System.out.println(ToAnalysis.parse(text));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>分词结果</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">中/f,新/a,网/n,11月/m,17日/m,电/n, ,据/p,外/f,媒/ng,报道/v,，/w,日本/ns,首相/n,安倍/nr,晋/j,三/m,称/v,，</div><div class="line">/w,有/v,机会/n,在/p,唐纳德/nr,•,特朗普/nr,获得/v,美国/ns,大选/vn,胜利/vn,后/f,，/w,成为/v,第一个/m,与/p,</div><div class="line">他/r,会晤/v,的/uj,外国/n,领导人/n,是/v,“/w,莫大/b,的/uj,荣幸/a,”/w,，/w,并/c,表示/v,希望/v,在/p,他们/r,</div><div class="line">之间/f,建立/v,信任/v,关系/n,。/w,报道/v,称/v,，/w,特朗普/nr,与/p,安倍/nr,或/c,将/d,于/p,当地/s,时间/n,</div><div class="line">17日/m,傍晚/t,在/p,纽约/ns,会谈/v,。/w</div></pre></td></tr></table></figure>
<p> 可以发现，文本已经分好词了，但是有些分词就不是很满意，如“中新网”就是一个网站名，应该就是一个词，又比如说安倍晋三是一个人名，应该就是一个词。要想解决这个问题就要加入自己的词库。</p>
<ul>
<li>自定义词库<br>现有以下词库：</li>
</ul>
<p>名字词库(name.dic)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">李连杰</div><div class="line">刘德华</div><div class="line">安倍晋三</div><div class="line">唐纳德.特兰普</div></pre></td></tr></table></figure></p>
<p>媒体词库(media.dic)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">中新网</div><div class="line">新华网</div></pre></td></tr></table></figure>
<p>以上两个词库我直接放在 <font color="ff0000">resources 文件夹</font>下。<br>通过UserDefineLibrary类中的静态方法 insertWord()来加载自己的词库。</p>
<ul>
<li>示例代码</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">import org.ansj.domain.Term;</div><div class="line">import org.ansj.library.UserDefineLibrary;</div><div class="line">import org.ansj.splitWord.analysis.ToAnalysis;</div><div class="line"></div><div class="line">import java.io.BufferedReader;</div><div class="line">import java.io.InputStream;</div><div class="line">import java.io.InputStreamReader;</div><div class="line">import java.util.List;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Created by lionel on 16/11/17.</div><div class="line"> */</div><div class="line">public class TextSegment &#123;</div><div class="line">    static &#123;</div><div class="line">        loadDictionary(&quot;/media.dic&quot;, &quot;media&quot;);</div><div class="line">        loadDictionary(&quot;/name.dic&quot;, &quot;name&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     *  从本地文件加载词库，并打上对应的标签，名字词库对应的词性是 name；媒体词库对应的词性是 media</div><div class="line">     *</div><div class="line">     * @param dic    本地词库路径</div><div class="line">     * @param speech 词性</div><div class="line">     */</div><div class="line">    public static void loadDictionary(String dic, String speech) &#123;</div><div class="line">        try &#123;</div><div class="line">            InputStream is = TextSegment.class.getResourceAsStream(dic);</div><div class="line">            BufferedReader reader = new BufferedReader(new InputStreamReader(is));</div><div class="line">            String line;</div><div class="line">            while ((line = reader.readLine()) != null) &#123;</div><div class="line">                String token = line.replaceAll(&quot;[\\r\\n]&quot;, &quot;&quot;).trim();</div><div class="line">                UserDefineLibrary.insertWord(token, speech, 1000);</div><div class="line">            &#125;</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * 实现分词</div><div class="line">     *</div><div class="line">     * @param text 文本</div><div class="line">     * @return 分词后的文本</div><div class="line">     */</div><div class="line">    public static List&lt;Term&gt; parse(String text) &#123;</div><div class="line">        if (text == null || text.length() == 0) &#123;</div><div class="line">            return null;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        return ToAnalysis.parse(text);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>分词结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">中新网/media,11月/m,17日/m,电/n, ,据/p,外/f,媒/ng,报道/v,，/w,日本/ns,首相/n,安倍晋三/name,称/v,，</div><div class="line">/w,有/v,机会/n,在/p,唐纳德•特朗普/name,获得/v,美国/ns,大选/vn,胜利/vn,后/f,，/w,成为/v,第一个/m,</div><div class="line">与/p,他/r,会晤/v,的/uj,外国/n,领导人/n,是/v,“/w,莫大/b,的/uj,荣幸/a,”/w,，/w,并/c,表示/v,希望/v,</div><div class="line">在/p,他们/r,之间/f,建立/v,信任/v,关系/n,。/w,报道/v,称/v,，/w,特朗普/nr,与/p,安倍/nr,或/c,将/d,</div><div class="line">于/p,当地/s,时间/n,17日/m,傍晚/t,在/p,纽约/ns,会谈/v,。/w</div></pre></td></tr></table></figure>
<p>从两次的分词结果比较结果可以看出，我们的词库已经起到了作用，对应的姓名和媒体都已经是单独的一个词了，而且词性也是自定义的词性。如，中新网/media，唐纳德•特朗普/name等等。这样就可以根据词性获取需要的信息了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如今，自然语言处理技术越来越成熟，越来越得到大家关注。许多互联网公司，如京东，阿里，新美大等互联网公司都有大量的文本评论数据，如何从这些文本中挖掘出有效的信息成为关键，这就需要应用自然语言处理技术，而对文本分词是自然语言处理的第一步，很关键。分词工具有很多&lt;a href=&quot;
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>mysql 分页查询优化</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/Mysql-%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/Mysql-分页查询优化/</id>
    <published>2017-03-21T11:35:22.000Z</published>
    <updated>2017-03-24T10:05:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>分页查询在 mysql 中常遇到，如以下语句 :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName limit 100,20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要0.03 sec。用时很短。<br>但是随着偏移量的增加，查询时间也随之增加。如下代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName limit 10000000,20</div></pre></td></tr></table></figure></p>
<p>用时大约需要32.43 sec，这个时间是不是就有点长了了？可以优化吗？答案是可以的。那么，该怎样优化？</p>
<p><strong>优化方法1</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName order by id limit 10000000,20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要17.71 sec，还是有点长。</p>
<p><strong>优化方法2</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName where id &gt;= (select id from TableName order by id limit 10000000,1) limit 20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要4.01 sec。</p>
<p><strong>优化方法3</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName a, (select id from TableName where status=1 order by id limit 10000000,10) b where a.id=b.id</div></pre></td></tr></table></figure></p>
<p>用时大约需要4.43sec。</p>
<p><strong>优化方法4</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName as a inner join (select id from TableName order by id limit 10000000,20) as b on a.id=b.id order by a.id;</div></pre></td></tr></table></figure></p>
<p>用时大约需要3.98sec。</p>
<p>可见优化方法2、优化方法3 和 优化方法4 运行时间差不多，相比于32.43 sec，效率提高八倍左右。</p>
<p>注：sql 语句中的 TableName指代的工作中一个有40000000多万记录的表。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分页查询在 mysql 中常遇到，如以下语句 :&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td cl
    
    </summary>
    
    
      <category term="Mysql" scheme="http://JiangFeng07.github.com/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>doc2vct算法实现</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/doc2vct%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/doc2vct算法实现/</id>
    <published>2017-03-21T10:03:56.000Z</published>
    <updated>2017-03-21T10:05:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章主要是实现Python 自然语言处理包 gensim 中用于长文本向量建模的 doc2vec算法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python3</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> multiprocessing</div><div class="line"><span class="keyword">import</span> os.path</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> utils</div><div class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> TaggedDocument, Doc2Vec</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDocs</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename)</span>:</span></div><div class="line">        self.filename = filename</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> open(self.filename, <span class="string">'rb'</span>):</div><div class="line">                pieces = utils.to_unicode(line).split()</div><div class="line">                tag = pieces[<span class="number">0</span>]</div><div class="line">                words = pieces[<span class="number">1</span>].split(<span class="string">','</span>)</div><div class="line">                <span class="keyword">yield</span> TaggedDocument(words, [tag])</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            logging.info(<span class="string">'e'</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    program = os.path.basename(sys.argv[<span class="number">0</span>])</div><div class="line">    logger = logging.getLogger(program)</div><div class="line"></div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s: %(levelname)s: %(message)s'</span>)</div><div class="line">    logging.root.setLevel(level=logging.INFO)</div><div class="line">    logger.info(<span class="string">"running %s"</span> % <span class="string">' '</span>.join(sys.argv))</div><div class="line"></div><div class="line">    <span class="comment"># check and process input arguments</span></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">4</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    inp, outp1, outp2 = sys.argv[<span class="number">1</span>:<span class="number">4</span>]</div><div class="line"></div><div class="line">    documents = MyDocs(inp)</div><div class="line">    <span class="comment">#建立模型</span></div><div class="line">    model = Doc2Vec(documents, size=<span class="number">200</span>, window=<span class="number">5</span>, min_count=<span class="number">20</span>, workers=multiprocessing.cpu_count())</div><div class="line"></div><div class="line">    <span class="comment"># trim unneeded model memory = use(much) less RAM</span></div><div class="line">    <span class="comment"># model.init_sims(replace=True)</span></div><div class="line">    <span class="comment">#保存模型</span></div><div class="line">    model.save(outp1)</div><div class="line">    model.save_word2vec_format(outp2, binary=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>说明一下：在MyDocs这个类中，我自定义了一个逐步读取文件的方法，因为在试验中我们发现，一个4个G 左右大小的文件在一个服务器内存为64G 的服务器上是不够用的，内存消耗非常之快，所以就看了一下源码中TaggedLineDocument和LineSentence这个类的源码，发现使用 yield这个关键字能很好的解决这个问题，便有了MyDocs类，实验结果表明，效果大大提高。有兴趣的同学可以看看 yield的用法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试模型</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Doc2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="comment"># check and process input arguments</span></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    file, word = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line"></div><div class="line">    <span class="comment">#加载模型</span></div><div class="line">    docvecs = Doc2Vec.load(file).docvecs</div><div class="line">    print(docvecs.most_similar(word))</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章主要是实现Python 自然语言处理包 gensim 中用于长文本向量建模的 doc2vec算法。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>word2vct算法实现</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/word2vct%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/word2vct算法实现/</id>
    <published>2017-03-21T09:50:51.000Z</published>
    <updated>2017-03-21T10:03:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章主要是实现Python 自然语言处理包 gensim 中用于词向量建模的 word2vec算法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    outputFile1, outputFile2 = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line"></div><div class="line">    sentences = [</div><div class="line">        <span class="string">"I think that most of us know by now that water is essential to our survival We’ve probably also all heard doctors say that drinking roughly eight glasses a day is ideal"</span>,</div><div class="line">        <span class="string">"yoyoyo you go home now to sleep"</span>]</div><div class="line"></div><div class="line">    vocab = [s.encode(<span class="string">'utf-8'</span>).decode().split() <span class="keyword">for</span> s <span class="keyword">in</span> sentences]</div><div class="line">    <span class="comment">#建立模型</span></div><div class="line">    model = Word2Vec(sentences, size=<span class="number">100</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, workers=<span class="number">4</span>)</div><div class="line">    <span class="comment">#保存模型</span></div><div class="line">    model.save(outputFile1)</div><div class="line">    model.save_word2vec_format(outputFile2, binary=<span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试模型</span></div><div class="line"><span class="comment"># encoding='utf-8'</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    file, word = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line">    <span class="comment">#从磁盘文件 file 加载模型</span></div><div class="line">    model = Word2Vec.load_word2vec_format(file, binary=<span class="keyword">False</span>)</div><div class="line">    print(model.most_similar(word))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章主要是实现Python 自然语言处理包 gensim 中用于词向量建模的 word2vec算法。&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;l
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow 安装和卸载</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/tensorflow-%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/tensorflow-安装和卸载/</id>
    <published>2017-03-21T09:07:31.000Z</published>
    <updated>2017-03-21T11:00:54.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于-virtualenv-安装"><a href="#基于-virtualenv-安装" class="headerlink" title="基于 virtualenv 安装"></a>基于 virtualenv 安装</h2><p>安装步骤如下：</p>
<ol>
<li>打开终端（a shell）;</li>
<li><p>安装 pip（如果之前没有安装的话） 和 virtualenv :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo easy_install pip</div><div class="line">$ sudo pip install --upgrade virtualenv</div></pre></td></tr></table></figure>
</li>
<li><p>建立一个新的 virtualenv 环境 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ virtualenv --system-site-packages ~/tensorflow</div></pre></td></tr></table></figure>
</li>
<li><p>激活 virtualenv :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ cd ~/tensorflow</div><div class="line">$ source bin/activate # 如果使用 bash, sh, ksh, 或者 zsh</div><div class="line">$ source bin/activate.csh # 如果使用 csh 或者 tcsh</div><div class="line">终端发生变化:</div><div class="line">(tensorflow)$</div></pre></td></tr></table></figure>
</li>
<li><p>安装 tensorflow :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install --upgrade tensorflow # for python 2.7</div><div class="line">pip3 install --upgrade tensorflow # for python 3.n</div></pre></td></tr></table></figure>
</li>
<li><p>测试是否安装成功 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(tensorflow) $ bin python</div><div class="line">Python 3.5.2 (default, Jul 28 2016, 21:28:00)</div><div class="line">[GCC 4.2.1 Compatible Apple LLVM 7.3.0 (clang-703.0.31)] on darwin</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)</div><div class="line">&gt;&gt;&gt; sess = tf.Session()</div><div class="line">&gt;&gt;&gt; print(sess.run(hello))</div><div class="line">b&apos;Hello, TensorFlow!&apos; # 安装成功</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="tensorflow-卸载"><a href="#tensorflow-卸载" class="headerlink" title="tensorflow 卸载"></a>tensorflow 卸载</h2><ol>
<li>执行卸载很简单，直接删除目录即可：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rm -r ~/tensorflow</div></pre></td></tr></table></figure></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基于-virtualenv-安装&quot;&gt;&lt;a href=&quot;#基于-virtualenv-安装&quot; class=&quot;headerlink&quot; title=&quot;基于 virtualenv 安装&quot;&gt;&lt;/a&gt;基于 virtualenv 安装&lt;/h2&gt;&lt;p&gt;安装步骤如下：&lt;/p&gt;
&lt;o
    
    </summary>
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/hello-world/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/hello-world/</id>
    <published>2017-03-21T08:56:25.000Z</published>
    <updated>2017-03-21T08:56:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
</feed>
