<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>江峰的技术博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://JiangFeng07.github.com/"/>
  <updated>2017-04-16T09:27:08.000Z</updated>
  <id>http://JiangFeng07.github.com/</id>
  
  <author>
    <name>Jiang Feng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Viterbi算法</title>
    <link href="http://JiangFeng07.github.com/2017/04/16/Viterbi%E7%AE%97%E6%B3%95/"/>
    <id>http://JiangFeng07.github.com/2017/04/16/Viterbi算法/</id>
    <published>2017-04-16T08:20:09.000Z</published>
    <updated>2017-04-16T09:27:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;前面已经介绍了隐马尔可夫模型，本篇博文主要是介绍用 viterbi 算法来解决 HMM 中的预测问题，也称为解码问题。<br>&emsp;&emsp;维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划(dynamic programming)求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。<br>&emsp;&emsp;根据动态规划原理，最优路径具有这样的特性：如果最优路径在时刻t通过$(i_t)^*$,那么这一路径从${i_t}^*$到终点${i_T}^*$的部分路径，对于从${i_t}^{*}$到${i_T}^*$的所有可能的部分路径来说，必须是最优的。因为假如不是这样，那么从${i_1}^*$到终点${i_T}^*$就有另一条更好的部分路径存在，如果把它和${i_1}^*$到终点${i_t}^*$的部分路径连接起来，就会形成一条比原来的路径更优的路径，这是矛盾的。依据这一原理，我们只需从时刻t=1开始，递推地计算在时刻t状态为i的各条部分路径的最大概率，直至得到时刻$t=T$状态为i的各条路径的最大概率。时刻$t=T$的最大概率即为最优路径的概率$P^*$,最优路径的终结点${i_T}^*$也同时得到。之后，为了找出最优路径的各个结点，从终结点${i_T}^*$开始，由后向前逐步求得结点${i_{T-1}}^*,…,{i_1}^*$得到最优路径这就是维特比算法。</p>
<ul>
<li><p>viterbi 算法<br>输入：模型$\lambda=(A,B,\pi)$和观测$O=(o_1,o_2,…,o_T)$;<br>输出：最优路径$({i_1}^*,…,{i_{T-1}}^*,{i_T}^*)$.<br>(1) 初始化</p>
<script type="math/tex; mode=display">\delta_1(i)=\pi_ib_i(o_i), \qquad i=1,2,...,N</script><script type="math/tex; mode=display">\psi_1(i)=0, \qquad i=1,2,...,N</script><p>(2) 递推.对$t=2,3,…,T$</p>
<script type="math/tex; mode=display">\delta_t(i)=max[\delta_{t-1}(j)a_{ji}]b_i(o_t), \qquad i=1,2,..,N;1\leq j\leq N</script><script type="math/tex; mode=display">\psi_t(i)=argmax[\delta_{t-1}(j)a_{ji}], \qquad i=1,2,...,N;1\leq j\leq N</script><p>(3) 终止</p>
<script type="math/tex; mode=display">P^*=max\delta_T(i), \qquad 1\leq j\leq N</script><script type="math/tex; mode=display">{i_T}^*=argmax[\delta_T(i)], \qquad 1\leq j\leq N</script><p>(4)最优路径回溯. 对$t=T-1,T-2,…,1$</p>
<script type="math/tex; mode=display">{i_t}^*=\psi_{t+1}({i_{t+1}^*})</script></li>
<li><p>viterbi算法实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.feng.nlp.algorithm;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.*;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by lionel on 17/4/11.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Viterbi</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; <span class="title">compute</span><span class="params">(String[] observe, String[] status, <span class="keyword">double</span>[] start_p, <span class="keyword">double</span>[][] transfer_p, <span class="keyword">double</span>[][] observe_p)</span> </span>&#123;</div><div class="line">        <span class="keyword">double</span>[][] theta = <span class="keyword">new</span> <span class="keyword">double</span>[observe.length][status.length];</div><div class="line">        <span class="keyword">int</span>[][] delta = <span class="keyword">new</span> <span class="keyword">int</span>[observe.length][status.length];</div><div class="line">        transfermation(start_p, transfer_p, observe_p);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; status.length; j++) &#123;</div><div class="line">            theta[<span class="number">0</span>][j] = start_p[j] + observe_p[j][<span class="number">0</span>];</div><div class="line">            delta[<span class="number">0</span>][j] = <span class="number">0</span>;</div><div class="line">        &#125;</div><div class="line">        Map&lt;String, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</div><div class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (String ele : observe) &#123;</div><div class="line">            <span class="keyword">if</span> (map.containsKey(ele)) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            map.put(ele, index);</div><div class="line">            index++;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; observe.length; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; status.length; j++) &#123;</div><div class="line">                <span class="keyword">int</span> direction = <span class="number">0</span>;</div><div class="line">                <span class="keyword">double</span> prob = Double.MAX_VALUE;</div><div class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; status.length; k++) &#123;</div><div class="line">                    <span class="keyword">double</span> tmpProb = theta[i - <span class="number">1</span>][k] + transfer_p[k][j] + observe_p[j][map.get(observe[i])];</div><div class="line">                    <span class="keyword">if</span> (tmpProb &lt; prob) &#123;</div><div class="line">                        prob = tmpProb;</div><div class="line">                        direction = k;</div><div class="line">                        theta[i][j] = prob;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">                delta[i][j] = direction;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"><span class="comment">//        for (int i = 0; i &lt; theta.length; i++) &#123;</span></div><div class="line"><span class="comment">//            for (int j = 0; j &lt; theta[i].length; j++) &#123;</span></div><div class="line"><span class="comment">//                System.out.print(theta[i][j] + " ");</span></div><div class="line"><span class="comment">//            &#125;</span></div><div class="line"><span class="comment">//            System.out.println();</span></div><div class="line"><span class="comment">//        &#125;</span></div><div class="line">        <span class="keyword">double</span> prob = Double.MAX_VALUE;</div><div class="line">        <span class="keyword">int</span> pos = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; status.length; j++) &#123;</div><div class="line">            <span class="keyword">if</span> (theta[observe.length - <span class="number">1</span>][j] &lt; prob) &#123;</div><div class="line">                prob = theta[observe.length - <span class="number">1</span>][j];</div><div class="line">                pos = j;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        List&lt;String&gt; res = <span class="keyword">new</span> ArrayList&lt;String&gt;();</div><div class="line">        res.add(status[pos]);</div><div class="line">        <span class="comment">//回溯路径</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = observe.length - <span class="number">1</span>; i &gt; <span class="number">0</span>; i--) &#123;</div><div class="line">            res.add(status[delta[i][pos]]);</div><div class="line">            pos = delta[i][pos];</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        Collections.reverse(res);</div><div class="line">        <span class="keyword">return</span> res;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">transfermation</span><span class="params">(<span class="keyword">double</span>[] start_p, <span class="keyword">double</span>[][] transfer_p, <span class="keyword">double</span>[][] observe_p)</span> </span>&#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; start_p.length; ++i) &#123;</div><div class="line">            start_p[i] = -Math.log(start_p[i]);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; transfer_p.length; ++i) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; transfer_p[i].length; ++j) &#123;</div><div class="line">                transfer_p[i][j] = -Math.log(transfer_p[i][j]);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; observe_p.length; ++i) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; observe_p[i].length; ++j) &#123;</div><div class="line">                observe_p[i][j] = -Math.log(observe_p[i][j]);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        String[] observe = &#123;<span class="string">"红"</span>, <span class="string">"白"</span>, <span class="string">"红"</span>&#125;;</div><div class="line">        String[] status = &#123;<span class="string">"1"</span>, <span class="string">"2"</span>, <span class="string">"3"</span>&#125;;</div><div class="line">        <span class="keyword">double</span>[] start_p = <span class="keyword">new</span> <span class="keyword">double</span>[]&#123;<span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.4</span>&#125;;</div><div class="line">        <span class="keyword">double</span>[][] transfer_p = <span class="keyword">new</span> <span class="keyword">double</span>[][]&#123;</div><div class="line">                &#123;<span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.3</span>&#125;,</div><div class="line">                &#123;<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>&#125;,</div><div class="line">                &#123;<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>&#125;</div><div class="line">        &#125;;</div><div class="line">        <span class="keyword">double</span>[][] observe_p = <span class="keyword">new</span> <span class="keyword">double</span>[][]&#123;</div><div class="line">                &#123;<span class="number">0.5</span>, <span class="number">0.5</span>&#125;,</div><div class="line">                &#123;<span class="number">0.4</span>, <span class="number">0.6</span>&#125;,</div><div class="line">                &#123;<span class="number">0.7</span>, <span class="number">0.3</span>&#125;</div><div class="line">        &#125;;</div><div class="line">        List&lt;String&gt; result = compute(observe, status, start_p, transfer_p, observe_p);</div><div class="line">        System.out.println(result);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>&emsp;&emsp;测试用例来源于李航老师的《统计机器学习》的例子。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;前面已经介绍了隐马尔可夫模型，本篇博文主要是介绍用 viterbi 算法来解决 HMM 中的预测问题，也称为解码问题。&lt;br&gt;&amp;emsp;&amp;emsp;维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划(dynamic programmi
    
    </summary>
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>隐马尔可夫模型（HMM）</title>
    <link href="http://JiangFeng07.github.com/2017/04/11/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88HMM%EF%BC%89/"/>
    <id>http://JiangFeng07.github.com/2017/04/11/隐马尔科夫模型（HMM）/</id>
    <published>2017-04-11T14:40:27.000Z</published>
    <updated>2017-04-11T16:23:25.000Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li><p>定义<br>设$Q$是所有可能的状态的集合，V是所有可能的观测的集合。</p>
<script type="math/tex; mode=display">Q=\{q_1,q_2,...,q_N\},V=\{v_1,v_2,...,v_M\}</script><p>其中，$N$是可能的状态数，$M$ 是可能的观测数。<br>状态$q$是不可见的，观测$v$是可见的。应用到词性标注系统，词就是$v$，词性就是$q$。<br>$I$是长度为$T$的状态序列，$O$是对应的观测序列。</p>
<script type="math/tex; mode=display">I=\{i_1,i_2,...,i_T\},O=\{o_1,o_2,...,o_T\}</script><p>$A$为状态转移概率矩阵：</p>
<script type="math/tex; mode=display">A=\left[a_{ij}\right]_{N\times N}</script><p>其中，</p>
<script type="math/tex; mode=display">a_{ij}=P(i_{t+1}=q_j|i_t=q_i),    i=1,2,...,N;j=1,2,...,N</script><p>是在时刻$t$处于状态$q_i$的条件下在时刻$t+1$转移到状态$q_j$的概率。<br>这实际在表述一个一阶的HMM，所作的假设是每个状态只跟前一个状态有关。<br>$B$是观测概率矩阵:</p>
<script type="math/tex; mode=display">B=\left[b_j(k)\right]_{N\times M}</script><p>其中，</p>
<script type="math/tex; mode=display">b_j(k)=P(o_t=v_k|i_t=q_j),    k=1,2,...,M;j=1,2,...,N</script><p>是在时刻t处于状态qj的条件下生成观测vk的概率（也就是所谓的“发射概率”）。<br>这实际上在作另一个假设，观测是由当前时刻的状态决定的，跟其他因素无关，这有点像Moore自动机。<br>π是初始状态概率向量：</p>
<script type="math/tex; mode=display">\pi=(\pi_i)</script><p>其中，<script type="math/tex">\pi=P(i_1=q_i),i=1,2,...,N</script><br>是时刻t=1处于状态$q_j$的概率。<br>隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵A和观测概率矩阵$B$决定,$\pi$和$A$决定状态序列，$B$决定观测序列。因此，隐马尔可夫模型$\lambda$可以用三元符号表示，即</p>
<script type="math/tex; mode=display">\lambda=\{A,B,\pi\}</script><p>状态转移概率矩阵$A$与初始状态概率向量$\pi$确定了隐藏的马尔可夫链，生成不可观测的状态序列。观测概率矩阵$B$确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。<br>从定义可知，隐马尔可夫模型作了两个基本假设：<br>(1)齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻$t#的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关。</p>
<script type="math/tex; mode=display">P(i_t|i_{t-1},o_{t-1},...,i_1,0_1)=P(i_t|i_{t-1}),t=1,2,...,T</script><p>从上式左右两边的复杂程度来看，齐次马尔可夫性假设简化了许多计算。<br>(2)观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关。</p>
<script type="math/tex; mode=display">P(o_t|i_t,o_T,i_{T-1},o_{T-1},...,i_{t+1},o_{t+1},i_t,o_t,...,i_1,o_1)=P(o_t|i_t)</script><p>简化了计算。</p>
</li>
<li><p>推倒<br>\begin{align}<br>P(i_1,i_2,…,i_n|o_1,o_2,…,o_n)&amp;=\frac{P(o_1,o_2,…,o_n|i_1,i_2,…,i_n)*P(i_1,i_2,…,i_n)}{P(o_1,o_2,…,o_n)}(1-1)\\<br>&amp;\rightarrow {P(o_1,o_2,…,o_n|i_1,i_2,…,i_n)}\ast{P(i_1,i_2,…,i_n)}(1-2)\\<br>&amp;\rightarrow \prod_{j=1}^np(o_j|i_j)P(i_{j+1}|i_j)(1-3)<br>\end{align}<br>由于$P(o_1,o_2,…,o_n)$是常量,所以求式1-1的问题可以转化为求式1-2的问题。<br>由假设1和2可把求式1-2的问题转化为求式1-3的问题。<br>由上可知，隐马尔的求解问题可以转化为求：</p>
<script type="math/tex; mode=display">max(\prod_{j=1}^np(o_j|i_j)P(i_{j+1}|i_j)</script><p>求解上述问题有两种方式，一种是枚举，当状态的集合和观测结合特别大时，这种方法显然不可行。一种可以有效求解的方法就是 Viterbi 算法，下一章节将用这个算法来进行求解。</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义&lt;br&gt;设$Q$是所有可能的状态的集合，V是所有可能的观测的集合。&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q=\{q_1,q_2,...,q_N\},V=\{v_1,v_2,...,v_M\}&lt;/scrip
    
    </summary>
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="http://JiangFeng07.github.com/2017/03/30/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://JiangFeng07.github.com/2017/03/30/逻辑回归/</id>
    <published>2017-03-29T16:09:19.000Z</published>
    <updated>2017-03-31T12:55:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>前一篇博客介绍了线性回归，纵使可以撇开 y 是离散值得事实，给定 x, 使用线性回归对 y 进行预测，可以找到很多示例说明这种预测结果不会很好，比如说，房价不可能随着面积大小线性增长。并且当我们知道 y 的取值范围在{0，1}时，预测结果大于 1 或者小于 0 已经没有了意义。怎样解决这个问题？可以使用逻辑回归。</p>
<p>逻辑回归于线性回归有很多相似之处，最大的不同在于他们的因变量不同。线性回归用来预测连续变量的值，而逻辑回归是用来求分类的，可以用来解决二分类问题，也可以用于解决多分类问题，但是解决二分类问题更为常见。</p>
<script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>称为logistic 函数或者 sigmod 函数。函数图像如下所示：<br><img src="http://onm4pqoqp.bkt.clouddn.com/sigmodfunction.png" alt=""><br>$g(z)$的导数$g′(z)$为:<br>\begin{align}<br>g′(z) &amp;= \frac{d}{dz}\frac{1}{1+e^{-z}}\\<br>&amp;= \frac{1}{(1+e^{-z})^2})(e^{-z}) \\<br>&amp;= \frac{1}{(1+e^{-z})}\cdot(1-\frac{1}{(1+e^{-z})})\\<br>&amp;= g(z)(1-g(z)).<br>\end{align}</p>
<script type="math/tex; mode=display">h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}</script><p>假设有:</p>
<script type="math/tex; mode=display">P(y=1 | x;\theta) = h_{\theta}(x)</script><script type="math/tex; mode=display">P(y=0 | x;\theta) = 1 - h_{\theta}(x)</script><p>更为一般的形式 :</p>
<script type="math/tex; mode=display">P(y|x;\theta) = (h_{\theta}(x))^y((1 - h_{\theta}(x)))^{1-y}</script><p>最大似然函数为：</p>
<p>\begin{align}<br>L(\theta) &amp;= p(\vec{y}|X;\theta)\\<br>&amp;= \prod_{i=1}^mp(y^{(i)} | x^{(i)};\theta)\\<br>&amp;= \prod_{i=1}^m(h_{\theta}(x^{(i)}))^{y^{(i)}} (1-h_{\theta}(x^{(i)}))^{1-y^{(i)}}<br>\end{align}</p>
<p>上式求对数得：<br>\begin{align}<br>l(\theta) &amp;= \log{L(\theta)}\\<br>&amp;= \sum_{i=1}^my^{(i)}\log h(x^{(i)})+(1-y^{(i)})\log(1-h(x^{(i)})))<br>\end{align}</p>
<p>对$l(\theta)$求导得:</p>
<p>\begin{align}<br>\frac{\partial}{\partial\theta_j}l(\theta) &amp;= \left(y\frac{1}{g(\theta^Tx)}-(1-y)\frac{1}{1-g(\theta^Tx)}\right)\frac{\partial}{\partial\theta_j}g(\theta^Tx)\\<br>&amp;= \left(y\frac{1}{g(\theta^Tx)}-(1-y)\frac{1}{1-g(\theta^Tx)}\right)g(\theta^Tx)(1-g(\theta^Tx))\frac{\partial}{\partial\theta_j}\theta^Tx\\<br>&amp;= \left(y(1-g(\theta^Tx)-(1-y)g(\theta^Tx)x_j\right) \\<br>&amp;= (y-h_{\theta}(x))x_j<br>\end{align}</p>
<p>所以随机梯度下降规则为 :</p>
<script type="math/tex; mode=display">\theta_j := \theta_j(y^{(i)}-h_{\theta}(x^{(i)}))(x_j)^{(i)}</script><p>实验代码如下 :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></div><div class="line">    dataMatrix = np.mat(dataMatIn)  <span class="comment"># 数据列表转换成矩阵</span></div><div class="line">    labelMat = np.mat(classLabels).transpose()  <span class="comment"># 类标签列表转换成矩阵</span></div><div class="line">    m, n = np.shape(dataMatrix)  <span class="comment"># 得到dataMatrix矩阵大小</span></div><div class="line">    alpha = <span class="number">0.001</span>  <span class="comment"># 每次上升的步长</span></div><div class="line">    maxCycles = <span class="number">500</span>  <span class="comment"># 迭代次数</span></div><div class="line">    weights = np.ones((n, <span class="number">1</span>))</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</div><div class="line">        h = sigmoid(dataMatrix * weights)  <span class="comment"># 计算假设函数h（列向量）</span></div><div class="line">        error = (labelMat - h)  <span class="comment"># 类标签和假设函数的误差</span></div><div class="line">        weights = weights + alpha * dataMatrix.transpose() * error  <span class="comment"># 对weights进行迭代更新</span></div><div class="line">    <span class="keyword">return</span> weights</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1</span> + np.exp(-inX))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></div><div class="line">    dataMat = []</div><div class="line">    labelMat = []</div><div class="line">    fr = open(<span class="string">'../resources/lr.txt'</span>)</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</div><div class="line">        lineArr = line.strip().split()</div><div class="line">        dataMat.append([<span class="number">1.0</span>, float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])  <span class="comment"># 得到数据列表</span></div><div class="line">        labelMat.append(int(lineArr[<span class="number">2</span>]))  <span class="comment"># 类标签</span></div><div class="line">    <span class="keyword">return</span> dataMat, labelMat</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    data, lable = loadDataSet()</div><div class="line">    weights = gradAscent(data, lable)</div><div class="line">    print(weights)</div></pre></td></tr></table></figure></p>
<p>源代码以及实验数据存储在<a href="https://github.com/JiangFeng07/JF-ML-python/tree/master/src/python/ml" target="_blank" rel="external">github</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一篇博客介绍了线性回归，纵使可以撇开 y 是离散值得事实，给定 x, 使用线性回归对 y 进行预测，可以找到很多示例说明这种预测结果不会很好，比如说，房价不可能随着面积大小线性增长。并且当我们知道 y 的取值范围在{0，1}时，预测结果大于 1 或者小于 0 已经没有了意
    
    </summary>
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="回归" scheme="http://JiangFeng07.github.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9B%9E%E5%BD%92/"/>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="回归" scheme="http://JiangFeng07.github.com/tags/%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="http://JiangFeng07.github.com/2017/03/25/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://JiangFeng07.github.com/2017/03/25/线性回归/</id>
    <published>2017-03-25T08:31:14.000Z</published>
    <updated>2017-03-31T13:01:55.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一元线性回归"><a href="#一元线性回归" class="headerlink" title="一元线性回归"></a>一元线性回归</h2><p>在机器学习中，线性回归被用来对连续型数据进行预测，来确定两种或者两种以上变量间的相互关系。本篇博客介绍线性回归的最简单的一种情况——一元线性回归。如下图，现在我们在图上画一系列的点，然后打算花一条线，这些点到这条线的距离尽可能的短。那么该怎么找到这条线了？线性回归就是很好的解决方法。<br><img src="http://onm4pqoqp.bkt.clouddn.com/LinearRegression.png" alt="" title="原始数据分布图"><br>首先，假设 y 和 x 满足下面的一元线性关系：</p>
<script type="math/tex; mode=display">y=\theta_0 + \theta_1x</script><p>这称为线性回归方程，其中$\theta_i$是回归系数。</p>
<p>使用 python 机器学习库 <a href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py" target="_blank" rel="external">sklearn</a> 来进行一元线性回归实验，实验代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python3</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    array = []</div><div class="line">    <span class="keyword">with</span> open(<span class="string">'../resources/lg.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> file:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</div><div class="line">            array.append(np.array(line.strip().split(<span class="string">"\t"</span>)).astype(np.float))</div><div class="line">    tmp = np.array(array)</div><div class="line">    x = tmp[<span class="number">0</span>:, <span class="number">0</span>:<span class="number">2</span>]</div><div class="line">    y = tmp[<span class="number">0</span>:, <span class="number">2</span>:<span class="number">3</span>]</div><div class="line">    linear = linear_model.LinearRegression()</div><div class="line">    linear.fit(x, y)</div><div class="line">    plt.plot(x, y, <span class="string">'b.'</span>)</div><div class="line">    y = linear.coef_ * x + linear.intercept_</div><div class="line">    plt.plot(x, y, <span class="string">'r'</span>)</div><div class="line">    plt.legend()</div><div class="line">    plt.show()</div><div class="line">    <span class="comment">#进行预测</span></div><div class="line">    x = np.array([<span class="number">1.0</span>, <span class="number">1.2</span>])</div><div class="line">    print(lr.predict(x))</div></pre></td></tr></table></figure></p>
<p>实验结果图形如下：<br><img src="http://onm4pqoqp.bkt.clouddn.com/LinearRegression2.png" alt="" title="线性回归实验结果图"><br>可以得出：</p>
<script type="math/tex; mode=display">y = 3.00774324 + 1.69532264x</script><p>此时预测 x=1.2时的值得 : 5.04213041.<br>源码和实验数据可以去我的 <a href="https://github.com/JiangFeng07/JF-ML-python/tree/master/src/python/ml" target="_blank" rel="external">github</a> 上进行下载。</p>
<h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>日常生活中，一个因变量是和多个自变量有关的，比如房价会和房子大小、房子面积、房子的地理位置等因素有关，一元线性关系不足以解决这样的问题，可以使用多元线性来解决。<br>现有方程：</p>
<script type="math/tex; mode=display">Y=X\beta</script><p>当 X 可逆时，会有</p>
<script type="math/tex; mode=display">\beta = X^{-1}Y</script><p>当 X 不可逆时，上述公式就不成立了。<br>这是就需要对上式进行转化了:</p>
<p>\begin{align}<br>Y=X\beta=&gt; X^TY=X^TX\beta \\<br>\end{align}<br>由于$X^TX$是可逆的,得</p>
<script type="math/tex; mode=display">\beta=(X^TX)^{-1}X^TY</script><p>现有示例方程：$y=2+3x_1+4x_2$<br>X=[[1,1,1],[1,1,2],[1,2,1]]<br>y=[[9],[13],[12]]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"></div><div class="line">X = [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]]</div><div class="line">y = [[<span class="number">9</span>], [<span class="number">13</span>], [<span class="number">12</span>]]</div><div class="line"></div><div class="line">model = LinearRegression()</div><div class="line">model.fit(X, y)</div><div class="line"></div><div class="line">x2 = [[<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>]]</div><div class="line">y2 = model.predict(x2)</div><div class="line">print(y2)</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[[ <span class="number">34.</span>]]</div></pre></td></tr></table></figure>
<p>带入函数，得y=2+3x4+4x5=34, 验证正确。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一元线性回归&quot;&gt;&lt;a href=&quot;#一元线性回归&quot; class=&quot;headerlink&quot; title=&quot;一元线性回归&quot;&gt;&lt;/a&gt;一元线性回归&lt;/h2&gt;&lt;p&gt;在机器学习中，线性回归被用来对连续型数据进行预测，来确定两种或者两种以上变量间的相互关系。本篇博客介绍线性回
    
    </summary>
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="回归" scheme="http://JiangFeng07.github.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9B%9E%E5%BD%92/"/>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow 入门</title>
    <link href="http://JiangFeng07.github.com/2017/03/25/tensorflow-%E5%85%A5%E9%97%A8/"/>
    <id>http://JiangFeng07.github.com/2017/03/25/tensorflow-入门/</id>
    <published>2017-03-25T04:31:44.000Z</published>
    <updated>2017-03-25T06:29:17.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>编辑距离</title>
    <link href="http://JiangFeng07.github.com/2017/03/25/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/"/>
    <id>http://JiangFeng07.github.com/2017/03/25/编辑距离/</id>
    <published>2017-03-25T04:10:33.000Z</published>
    <updated>2017-03-25T06:33:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>什么是编辑距离？<br>看下百度百科的介绍：编辑距离（Edit Distance），又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将<font color="ff000">一个字符替换成另一个字符</font>，<font color="ff000">插入一个字符</font>，<font color="ff000">删除一个字符</font>。一般来说，<font color="ff000">编辑距离越小，两个串的相似度越大</font>。<br>比如说:<br>    kitten-&gt;sitten （k→s）<br>    sitten-&gt;sittin （e→i）<br>    sittin-&gt;sitting （插入g）</p>
<p>找出字符串s1和字符串s2的编辑距离，就是求出字符串s1变成字符串s2的最小操作步骤，主要操作步骤有三种：交换、删除、插入。可以利用动态规划的思想来求解字符转 s1和字符串s2的编辑距离。</p>
<p>动态规划公式如下所示：</p>
<p><img src="http://img.blog.csdn.net/20160222115529695" alt="编辑距离公式"></p>
<ul>
<li>代码示例</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.myapp.ml.nlp;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by lionel on 16/12/21.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EditDistance</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">editDistance</span><span class="params">(String A, String B)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (StringUtils.isBlank(A + B)) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> lengthA = A.length();</div><div class="line">        <span class="keyword">int</span> lengthB = B.length();</div><div class="line">        <span class="keyword">int</span>[][] distance = <span class="keyword">new</span> <span class="keyword">int</span>[lengthA + <span class="number">1</span>][lengthB + <span class="number">1</span>];</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; lengthA; i++) &#123;</div><div class="line">            distance[i][<span class="number">0</span>] = i;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; lengthB; i++) &#123;</div><div class="line">            distance[<span class="number">0</span>][i] = i;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; lengthA; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; lengthB; j++) &#123;</div><div class="line">                <span class="keyword">int</span> cost = A.charAt(i - <span class="number">1</span>) == B.charAt(j - <span class="number">1</span>) ? <span class="number">0</span> : <span class="number">1</span>;</div><div class="line">                <span class="keyword">int</span> deletion = distance[i - <span class="number">1</span>][j] + <span class="number">1</span>;</div><div class="line">                <span class="keyword">int</span> insertion = distance[i][j - <span class="number">1</span>] + <span class="number">1</span>;</div><div class="line">                <span class="keyword">int</span> exchange = distance[i - <span class="number">1</span>][j - <span class="number">1</span>] + cost;</div><div class="line">                distance[i][j] = Math.min(exchange, Math.min(insertion, deletion));</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> distance[lengthA - <span class="number">1</span>][lengthB - <span class="number">1</span>];</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        EditDistance editDistance = <span class="keyword">new</span> EditDistance();</div><div class="line">        String str2 = <span class="string">"kitten"</span>;</div><div class="line">        String str1 = <span class="string">"sitting"</span>;</div><div class="line">        System.out.println(editDistance.editDistance(str1, str2));<span class="comment">//3</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;什么是编辑距离？&lt;br&gt;看下百度百科的介绍：编辑距离（Edit Distance），又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将&lt;font color=&quot;ff000&quot;&gt;一个字符替换成另一个字符&lt;/font&gt;，
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>终端常用快捷键</title>
    <link href="http://JiangFeng07.github.com/2017/03/25/%E7%BB%88%E7%AB%AF%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    <id>http://JiangFeng07.github.com/2017/03/25/终端常用快捷键/</id>
    <published>2017-03-25T02:56:48.000Z</published>
    <updated>2017-03-25T04:08:52.000Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li>终端常用快捷键<br>⌘ + r = clear，而且只是换到新一屏，不会像 clear 一样创建一个空屏<br>ctrl + u 清空当前行，无论光标在什么位置<br>新建窗口：command + t<br>垂直分屏：command + d<br>水平分屏：command + shift + d<br>切换屏幕：command + option + 方向键 command + [ 或 command + ]<br>删除光标之前的字符：ctrl + h<br>删除光标之前的单词：ctrl + w<br>删除到文本末尾：ctrl + k<br>定位当前行首部：control + a<br>定位当前行尾部：contorl + e<br>清屏：command + r  或者 ctrl + l</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;终端常用快捷键&lt;br&gt;⌘ + r = clear，而且只是换到新一屏，不会像 clear 一样创建一个空屏&lt;br&gt;ctrl + u 清空当前行，无论光标在什么位置&lt;br&gt;新建窗口：command + t&lt;br&gt;垂直分屏：command + d&lt;br&gt;水平分屏：c
    
    </summary>
    
    
      <category term="工具" scheme="http://JiangFeng07.github.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客使用MathJax数学公式</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/Hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8MathJax%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/Hexo博客使用MathJax数学公式/</id>
    <published>2017-03-24T11:29:15.000Z</published>
    <updated>2017-03-31T12:57:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇博文介绍在 Hexo 博客使用 MathJax 数学公式。</p>
<ol>
<li><p>更改 Hexo 的 markdown 渲染引擎，安装 hexo-renderer-kramed</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">npm uninstall hexo-renderer-marked --save</div><div class="line">npm install hexo-renderer-kramed --save</div></pre></td></tr></table></figure>
</li>
<li><p>修改 hexo 博客站点目录（node_modules\kramed\lib\rules\）下的 inline.js 文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//  escape: /^\\([\\`*&#123;&#125;\[\]()<span class="comment">#$+\-.!_&gt;])/,</span></div><div class="line">escape: /^\\([`*\[\]()<span class="comment">#$+\-.!_&gt;])/,</span></div><div class="line"></div><div class="line">//  em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</div><div class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</div></pre></td></tr></table></figure>
</li>
<li><p>重新启动hexo</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server</div></pre></td></tr></table></figure>
<p> 如果还不行，查看你的主题目录下_config.yml是否开启 mathjax，开启如下：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># MathJax Support</span></div><div class="line">mathjax:</div><div class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></div><div class="line">  per_page: <span class="literal">true</span></div></pre></td></tr></table></figure>
<p> 还有就是在你写的博客文章的Front-matter里打开mathjax开关，如下：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">---</div><div class="line">title: 文章名</div><div class="line">date: 2017-03-23 19:01:30</div><div class="line">tags:</div><div class="line">mathjax: <span class="literal">true</span></div><div class="line">--</div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇博文介绍在 Hexo 博客使用 MathJax 数学公式。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;更改 Hexo 的 markdown 渲染引擎，安装 hexo-renderer-kramed&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table
    
    </summary>
    
      <category term="工具" scheme="http://JiangFeng07.github.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://JiangFeng07.github.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>朴素贝叶斯算法</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/朴素贝叶斯/</id>
    <published>2017-03-24T10:28:43.000Z</published>
    <updated>2017-03-31T12:58:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>贝叶斯定理想必大家很早就已经了解，朴素贝叶斯算法就是基于贝叶斯定理提出的一种监督机器学习算法。为什么叫“朴素”了？那是因为朴素贝叶斯分类器基于一个简单的假定：给定目标值时属性之间相互条件独立。给定类变量 y (这里一个样本仅属于一类) 和一个相互独立的特征向量 $x_1$ 到 $x_n$，贝叶斯定理可得到如下关系：</p>
<script type="math/tex; mode=display">P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)}
                                 {P(x_1, \dots, x_n)}</script><p>使用朴素（naive）的假设：每个特征之间相互独立：</p>
<script type="math/tex; mode=display">P(x_i | y, x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n) = P(x_i | y)</script><p>对于所有的$i$,这个关系可以简化为：</p>
<script type="math/tex; mode=display">P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)}
                                 {P(x_1, \dots, x_n)}</script><p>由于${P(x_1, \dots, x_n)}$的值当给定的特征不变式是固定的，所以可以得到以下分类规则：</p>
<script type="math/tex; mode=display">P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y)</script><p>并且我们可以使用最大后验概率（MAP）估计来估计$P(y) $ ,$P(x_i \mid y)$;<br>不同的朴素贝叶斯分类器的不同之处在于：它们对$P(x_i \mid y)$的分布的认识和假设不同。目前常用的有高斯模型、多项式模型和伯努利模型这三种模型。本文主要介绍高斯模型以及对应的 python 实现。</p>
<h2 id="朴素贝叶斯算法-高斯模型"><a href="#朴素贝叶斯算法-高斯模型" class="headerlink" title="朴素贝叶斯算法 高斯模型"></a>朴素贝叶斯算法 高斯模型</h2><p>高斯模型假设这些一个特征的所有属于某个类别的观测值符合高斯分布:</p>
<script type="math/tex; mode=display">P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)</script><h2 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python3</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> math</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 根据文件路径加载数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(file_name)</span>:</span></div><div class="line">    file = open(file_name)</div><div class="line">    data = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</div><div class="line">        tmpline = line.split(<span class="string">' '</span>)</div><div class="line">        tmp = []</div><div class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> tmpline:</div><div class="line">            tmp.append(float(x))</div><div class="line">        data.append(tmp)</div><div class="line">    <span class="keyword">return</span> data</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 数据分为训练数据 train_set 和测试数据 test_set</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data</span><span class="params">(data, split_ratio)</span>:</span></div><div class="line">    train_size = int(len(data) * split_ratio)</div><div class="line">    train_set = []</div><div class="line">    test_set = list(data)</div><div class="line">    <span class="keyword">while</span> len(train_set) &lt; train_size:</div><div class="line">        index = random.randrange(len(test_set))</div><div class="line">        train_set.append(test_set.pop(index))</div><div class="line">    <span class="keyword">return</span> [train_set, test_set]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 根据结果分类</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">separate_by_class</span><span class="params">(data)</span>:</span></div><div class="line">    y = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        vector = data[i]</div><div class="line">        <span class="keyword">if</span> vector[<span class="number">-1</span>] <span class="keyword">not</span> <span class="keyword">in</span> y:</div><div class="line">            y[vector[<span class="number">-1</span>]] = []</div><div class="line">        y[vector[<span class="number">-1</span>]].append(vector)</div><div class="line">    <span class="keyword">return</span> y</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 计算平均值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">average</span><span class="params">(numbers)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum(numbers) / float(len(numbers))</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 计算样本方差</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stdev</span><span class="params">(numbers)</span>:</span></div><div class="line">    avg = average(numbers)</div><div class="line">    variance = sum([pow(x - avg, <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> numbers]) / float(len(numbers) - <span class="number">1</span>)</div><div class="line">    <span class="keyword">return</span> math.sqrt(variance)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 计算每个属性的平均值和样本方差</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">summarize</span><span class="params">(data)</span>:</span></div><div class="line">    summaries = [(average(attribute), stdev(attribute)) <span class="keyword">for</span> attribute <span class="keyword">in</span> zip(*data)]</div><div class="line">    <span class="keyword">del</span> summaries[<span class="number">-1</span>]</div><div class="line">    <span class="keyword">return</span> summaries</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">summaries_by_class</span><span class="params">(data)</span>:</span></div><div class="line">    y = separate_by_class(data)</div><div class="line">    summaries = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> classValue, instances <span class="keyword">in</span> y.items():</div><div class="line">        summaries[classValue] = summarize(instances)</div><div class="line">    <span class="keyword">return</span> summaries</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 计算高斯分布</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_Probability</span><span class="params">(x, avg, stdev)</span>:</span></div><div class="line">    exponent = math.exp((<span class="number">-1</span>) * (math.pow(x - avg, <span class="number">2</span>) / (<span class="number">2</span> * math.pow(stdev, <span class="number">2</span>))))</div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> / (math.sqrt(<span class="number">2</span> * math.pi) * stdev)) * exponent</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 计算输入向量的贝叶斯概率</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateClassProbabilities</span><span class="params">(summaries, inputVector)</span>:</span></div><div class="line">    probabilities = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> classValue, classSummaries <span class="keyword">in</span> summaries.items():</div><div class="line">        probabilities[classValue] = <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(classSummaries)):</div><div class="line">            avg, stdev = classSummaries[i]</div><div class="line">            x = inputVector[i]</div><div class="line">            probabilities[classValue] *= calculate_Probability(x, avg, stdev)</div><div class="line">    <span class="keyword">return</span> probabilities</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 找到最大的值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(summaries, inputVector)</span>:</span></div><div class="line">    probabilities = calculateClassProbabilities(summaries, inputVector)</div><div class="line">    bestLabel, bestProb = <span class="keyword">None</span>, <span class="number">-1</span></div><div class="line">    <span class="keyword">for</span> classValue, probability <span class="keyword">in</span> probabilities.items():</div><div class="line">        <span class="keyword">if</span> bestLabel <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> probability &gt; bestProb:</div><div class="line">            bestProb = probability</div><div class="line">            bestLabel = classValue</div><div class="line">    <span class="keyword">return</span> bestLabel</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPredictions</span><span class="params">(summaries, testSet)</span>:</span></div><div class="line">    predictions = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testSet)):</div><div class="line">        result = predict(summaries, testSet[i])</div><div class="line">        predictions.append(result)</div><div class="line">    <span class="keyword">return</span> predictions</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 计算预测正确率</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAccuracy</span><span class="params">(testSet, predictions)</span>:</span></div><div class="line">    correct = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testSet)):</div><div class="line">        <span class="keyword">if</span> testSet[i][<span class="number">-1</span>] == predictions[i]:</div><div class="line">            correct += <span class="number">1</span></div><div class="line">    <span class="keyword">return</span> (correct / float(len(testSet))) * <span class="number">100.0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    data = load_data(<span class="string">"/tmp/pima-indians-diabetes.txt"</span>)</div><div class="line">    trainSet, testSet = split_data(data, <span class="number">0.8</span>)</div><div class="line">    summaries = summaries_by_class(trainSet)</div><div class="line">    print(</div><div class="line">        <span class="string">'split &#123;0&#125; rows data into &#123;1&#125; rows trainData and &#123;2&#125; rows testData'</span>.format(len(data), len(trainSet), len(testSet)))</div><div class="line">    predictions = getPredictions(summaries, testSet)</div><div class="line">    accuracy = getAccuracy(testSet, predictions)</div><div class="line">    print(<span class="string">'Accuracy:&#123;0&#125;%'</span>.format(accuracy))</div></pre></td></tr></table></figure>
<p>本实验进行了10次测试，得到的平均正确率为74.42%。</p>
<ul>
<li>参考资料：<ul>
<li><a href="http://sklearn.lzjqsdd.com/modules/naive_bayes.html#gaussian-naive-bayes" target="_blank" rel="external">朴素贝叶斯</a></li>
<li><a href="http://python.jobbole.com/81019/" target="_blank" rel="external">机器学习之用Python从零实现贝叶斯分类器</a></li>
</ul>
</li>
<li>数据集<ul>
<li><a href="http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data" target="_blank" rel="external">数据集地址</a></li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;贝叶斯定理想必大家很早就已经了解，朴素贝叶斯算法就是基于贝叶斯定理提出的一种监督机器学习算法。为什么叫“朴素”了？那是因为朴素贝叶斯分类器基于一个简单的假定：给定目标值时属性之间相互条件独立。给定类变量 y (这里一个样本仅属于一类) 和一个相互独立的特征向量 $x_1$ 
    
    </summary>
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降法</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/梯度下降法/</id>
    <published>2017-03-24T10:09:15.000Z</published>
    <updated>2017-03-31T12:59:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降法，又叫最速下降法，是一种最优化算法。它用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。<br>梯度下降法的计算过程就是沿着梯度下降的方向求解极小值。（亦可以沿着梯度上升的方向求解极大值）。它的迭代公式为:</p>
<script type="math/tex; mode=display">a_{k+1}=a_{k}+\gamma_ks^{-(k)}(式1-1)</script><p>其中，$s^{-(k)}$代表的是梯度的负方向，$\gamma_k$表示梯度方向上的搜索步长。梯度方向可以通过求导得到，步长的设定则比较麻烦，太大的容易发散，找不到极小值的点，太小的话则收敛的速度比较慢。</p>
<ul>
<li>示例<br>现有函数$f(x)=x^4-3x^3+2$,则利用梯度下降方法解题的步骤如下：<br>1.求梯度，即对函数求导，$f(x)=4x^3-9x^2$；<br>2.根据式1-1，向梯度相反的方向移动 $x$；<br>3.循环迭代步骤2，直到x的值变化到使得$f(x)$在两次迭代之间的差值足够小，比如0.00000001，也就是说，直到两次迭代计算出来的$f(x)$基本没有变化，则说明此时$f(x)$已经达到局部最小值了。<br>4.此时，输出 $x$，此时求得的 $x$ 就是使得$f(x)$取得最小值的 x 的值。</li>
<li>代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#python 代码</span></div><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"></div><div class="line">x_old = <span class="number">0</span></div><div class="line">x_new = <span class="number">6</span></div><div class="line">gamma = <span class="number">0.01</span></div><div class="line">precision = <span class="number">0.00000001</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># x = Symbol("x")</span></div><div class="line"><span class="comment"># f = (x ** 4) - (3 * (x ** 3)) + 2</span></div><div class="line"></div><div class="line"><span class="comment">#梯度下降算法</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">df</span><span class="params">(x)</span>:</span></div><div class="line">    y = <span class="number">4</span> * x**<span class="number">3</span> - <span class="number">9</span> * x**<span class="number">2</span></div><div class="line">    <span class="keyword">return</span> y</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">while</span> abs(x_new - x_old) &gt; precision:</div><div class="line">    x_old = x_new</div><div class="line">    x_new += -gamma * df(x_old)</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"The local minimum occurs at"</span>, x_new//The local minimum occurs at <span class="number">2.24999996819</span></div></pre></td></tr></table></figure>
<p>利用数学知识可以求得函数$f(x)=x^4-3x^3+2$的极小值在$\frac{9}{4}$取得，即2.25，代码求得的结果是2.24999996819，已经满足小于0.00000001的条件，代码有效。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;梯度下降法，又叫最速下降法，是一种最优化算法。它用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。&lt;br&gt;梯度下降法的计算过程就是沿着梯度下降的方向求解极小值。（亦可以沿着梯度上升的方向求解极大值）。它的迭代公式为:&lt;/p&gt;
&lt;script type=&quot;
    
    </summary>
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://JiangFeng07.github.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ansj分词简单案例</title>
    <link href="http://JiangFeng07.github.com/2017/03/24/ansj%E5%88%86%E8%AF%8D%E7%AE%80%E5%8D%95%E6%A1%88%E4%BE%8B/"/>
    <id>http://JiangFeng07.github.com/2017/03/24/ansj分词简单案例/</id>
    <published>2017-03-24T08:35:52.000Z</published>
    <updated>2017-03-25T03:09:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>如今，自然语言处理技术越来越成熟，越来越得到大家关注。许多互联网公司，如京东，阿里，新美大等互联网公司都有大量的文本评论数据，如何从这些文本中挖掘出有效的信息成为关键，这就需要应用自然语言处理技术，而对文本分词是自然语言处理的第一步，很关键。分词工具有很多<a href="http://ictclas.nlpir.org/" target="_blank" rel="external">NLPIR</a>、<a href="http://code.google.com/p/ik-analyzer/" target="_blank" rel="external">IKAnalyzer</a>、<a href="https://www.baidu.com/link?url=Bv6PmRepvb8vA06WGOUleDBM6Yd-fvmNnTkGOZGDRXrmaMTU2DVEJ7Mt2HAPrZi-&amp;wd=&amp;eqid=b847872c0002fb5400000004582d599d" target="_blank" rel="external">stanford nlp</a>等等，本篇博文将介绍我所使用的分词工具 <a href="https://github.com/NLPchina/ansj_seg" target="_blank" rel="external">Ansj</a> 的使用。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul>
<li><p>下载 jar</p>
<p>访问<a href="http://maven.nlpcn.org/org/ansj/" target="_blank" rel="external">http://maven.nlpcn.org/org/ansj/ </a>下载ansj-seg，倒入自己的 IDE，就可以了。如果你使用 maven，可以添加以下依赖：</p>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;!-- 增加新的maven源 --&gt;</div><div class="line">&lt;repositories&gt;</div><div class="line">    &lt;repository&gt;</div><div class="line">        &lt;id&gt;mvn-repo&lt;/id&gt;</div><div class="line">        &lt;url&gt;http://maven.nlpcn.org/&lt;/url&gt;</div><div class="line">    &lt;/repository&gt;</div><div class="line">&lt;/repositories&gt;</div><div class="line"></div><div class="line"></div><div class="line">&lt;dependencies&gt;</div><div class="line">    ....</div><div class="line"></div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.ansj&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;ansj_seg&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;5.0.1&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    ....</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h2 id="示例演示"><a href="#示例演示" class="headerlink" title="示例演示"></a>示例演示</h2><p>先来看一个简单的的 demo 演示。</p>
<ul>
<li>Demo</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.ansj.splitWord.analysis.ToAnalysis;</div><div class="line"><span class="keyword">import</span> org.junit.Test;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by lionel on 16/11/17.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AnsjTest</span> </span>&#123;</div><div class="line">    <span class="meta">@Test</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span></span>&#123;</div><div class="line">        String text=<span class="string">"中新网11月17日电 据外媒报道，日本首相安倍晋三称，有机会在唐纳德•特朗普获得美国大选胜利后，成为第一个与他会晤的外国领导人是“莫大的荣幸”，并表示希望在他们之间建立信任关系。报道称，特朗普与安倍或将于当地时间17日傍晚在纽约会谈。"</span>;</div><div class="line">        System.out.println(ToAnalysis.parse(text));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>分词结果</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">中/f,新/a,网/n,11月/m,17日/m,电/n, ,据/p,外/f,媒/ng,报道/v,，/w,日本/ns,首相/n,安倍/nr,晋/j,三/m,称/v,，</div><div class="line">/w,有/v,机会/n,在/p,唐纳德/nr,•,特朗普/nr,获得/v,美国/ns,大选/vn,胜利/vn,后/f,，/w,成为/v,第一个/m,与/p,</div><div class="line">他/r,会晤/v,的/uj,外国/n,领导人/n,是/v,“/w,莫大/b,的/uj,荣幸/a,”/w,，/w,并/c,表示/v,希望/v,在/p,他们/r,</div><div class="line">之间/f,建立/v,信任/v,关系/n,。/w,报道/v,称/v,，/w,特朗普/nr,与/p,安倍/nr,或/c,将/d,于/p,当地/s,时间/n,</div><div class="line">17日/m,傍晚/t,在/p,纽约/ns,会谈/v,。/w</div></pre></td></tr></table></figure>
<p> 可以发现，文本已经分好词了，但是有些分词就不是很满意，如“中新网”就是一个网站名，应该就是一个词，又比如说安倍晋三是一个人名，应该就是一个词。要想解决这个问题就要加入自己的词库。</p>
<ul>
<li>自定义词库<br>现有以下词库：</li>
</ul>
<p>名字词库(name.dic)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">李连杰</div><div class="line">刘德华</div><div class="line">安倍晋三</div><div class="line">唐纳德.特兰普</div></pre></td></tr></table></figure></p>
<p>媒体词库(media.dic)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">中新网</div><div class="line">新华网</div></pre></td></tr></table></figure>
<p>以上两个词库我直接放在 <font color="ff0000">resources 文件夹</font>下。<br>通过UserDefineLibrary类中的静态方法 insertWord()来加载自己的词库。</p>
<ul>
<li>示例代码</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.ansj.domain.Term;</div><div class="line"><span class="keyword">import</span> org.ansj.library.UserDefineLibrary;</div><div class="line"><span class="keyword">import</span> org.ansj.splitWord.analysis.ToAnalysis;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.BufferedReader;</div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.io.InputStreamReader;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by lionel on 16/11/17.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TextSegment</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        loadDictionary(<span class="string">"/media.dic"</span>, <span class="string">"media"</span>);</div><div class="line">        loadDictionary(<span class="string">"/name.dic"</span>, <span class="string">"name"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     *  从本地文件加载词库，并打上对应的标签，名字词库对应的词性是 name；媒体词库对应的词性是 media</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> dic    本地词库路径</div><div class="line">     * <span class="doctag">@param</span> speech 词性</div><div class="line">     */</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">loadDictionary</span><span class="params">(String dic, String speech)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            InputStream is = TextSegment.class.getResourceAsStream(dic);</div><div class="line">            BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(is));</div><div class="line">            String line;</div><div class="line">            <span class="keyword">while</span> ((line = reader.readLine()) != <span class="keyword">null</span>) &#123;</div><div class="line">                String token = line.replaceAll(<span class="string">"[\\r\\n]"</span>, <span class="string">""</span>).trim();</div><div class="line">                UserDefineLibrary.insertWord(token, speech, <span class="number">1000</span>);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 实现分词</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> text 文本</div><div class="line">     * <span class="doctag">@return</span> 分词后的文本</div><div class="line">     */</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;Term&gt; <span class="title">parse</span><span class="params">(String text)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (text == <span class="keyword">null</span> || text.length() == <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> ToAnalysis.parse(text);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>分词结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">中新网/media,11月/m,17日/m,电/n, ,据/p,外/f,媒/ng,报道/v,，/w,日本/ns,首相/n,安倍晋三/name,称/v,，</div><div class="line">/w,有/v,机会/n,在/p,唐纳德•特朗普/name,获得/v,美国/ns,大选/vn,胜利/vn,后/f,，/w,成为/v,第一个/m,</div><div class="line">与/p,他/r,会晤/v,的/uj,外国/n,领导人/n,是/v,“/w,莫大/b,的/uj,荣幸/a,”/w,，/w,并/c,表示/v,希望/v,</div><div class="line">在/p,他们/r,之间/f,建立/v,信任/v,关系/n,。/w,报道/v,称/v,，/w,特朗普/nr,与/p,安倍/nr,或/c,将/d,</div><div class="line">于/p,当地/s,时间/n,17日/m,傍晚/t,在/p,纽约/ns,会谈/v,。/w</div></pre></td></tr></table></figure>
<p>从两次的分词结果比较结果可以看出，我们的词库已经起到了作用，对应的姓名和媒体都已经是单独的一个词了，而且词性也是自定义的词性。如，中新网/media，唐纳德•特朗普/name等等。这样就可以根据词性获取需要的信息了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如今，自然语言处理技术越来越成熟，越来越得到大家关注。许多互联网公司，如京东，阿里，新美大等互联网公司都有大量的文本评论数据，如何从这些文本中挖掘出有效的信息成为关键，这就需要应用自然语言处理技术，而对文本分词是自然语言处理的第一步，很关键。分词工具有很多&lt;a href=&quot;
    
    </summary>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>mysql 分页查询优化</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/Mysql-%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/Mysql-分页查询优化/</id>
    <published>2017-03-21T11:35:22.000Z</published>
    <updated>2017-03-24T10:31:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>分页查询在 mysql 中常遇到，如以下语句 :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName limit 100,20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要0.03 sec。用时很短。<br>但是随着偏移量的增加，查询时间也随之增加。如下代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName limit 10000000,20</div></pre></td></tr></table></figure></p>
<p>用时大约需要32.43 sec，这个时间是不是就有点长了了？可以优化吗？答案是可以的。那么，该怎样优化？</p>
<p><strong>优化方法1</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName order by id limit 10000000,20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要17.71 sec，还是有点长。</p>
<p><strong>优化方法2</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName where id &gt;= (select id from TableName order by id limit 10000000,1) limit 20;</div></pre></td></tr></table></figure></p>
<p>用时大约需要4.01 sec。</p>
<p><strong>优化方法3</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName a, (select id from TableName where status=1 order by id limit 10000000,10) b where a.id=b.id</div></pre></td></tr></table></figure></p>
<p>用时大约需要4.43sec。</p>
<p><strong>优化方法4</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from TableName as a inner join (select id from TableName order by id limit 10000000,20) as b on a.id=b.id order by a.id;</div></pre></td></tr></table></figure></p>
<p>用时大约需要3.98sec。</p>
<p>可见优化方法2、优化方法3 和 优化方法4 运行时间差不多，相比于32.43 sec，效率提高八倍左右。</p>
<p>注：sql 语句中的 TableName指代的工作中一个有40000000多万记录的表。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分页查询在 mysql 中常遇到，如以下语句 :&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td cl
    
    </summary>
    
    
      <category term="Mysql" scheme="http://JiangFeng07.github.com/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>doc2vct算法实现</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/doc2vct%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/doc2vct算法实现/</id>
    <published>2017-03-21T10:03:56.000Z</published>
    <updated>2017-03-31T12:57:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章主要是实现Python 自然语言处理包 gensim 中用于长文本向量建模的 doc2vec算法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python3</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> multiprocessing</div><div class="line"><span class="keyword">import</span> os.path</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> utils</div><div class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> TaggedDocument, Doc2Vec</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDocs</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename)</span>:</span></div><div class="line">        self.filename = filename</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> open(self.filename, <span class="string">'rb'</span>):</div><div class="line">                pieces = utils.to_unicode(line).split()</div><div class="line">                tag = pieces[<span class="number">0</span>]</div><div class="line">                words = pieces[<span class="number">1</span>].split(<span class="string">','</span>)</div><div class="line">                <span class="keyword">yield</span> TaggedDocument(words, [tag])</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            logging.info(<span class="string">'e'</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    program = os.path.basename(sys.argv[<span class="number">0</span>])</div><div class="line">    logger = logging.getLogger(program)</div><div class="line"></div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s: %(levelname)s: %(message)s'</span>)</div><div class="line">    logging.root.setLevel(level=logging.INFO)</div><div class="line">    logger.info(<span class="string">"running %s"</span> % <span class="string">' '</span>.join(sys.argv))</div><div class="line"></div><div class="line">    <span class="comment"># check and process input arguments</span></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">4</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    inp, outp1, outp2 = sys.argv[<span class="number">1</span>:<span class="number">4</span>]</div><div class="line"></div><div class="line">    documents = MyDocs(inp)</div><div class="line">    <span class="comment">#建立模型</span></div><div class="line">    model = Doc2Vec(documents, size=<span class="number">200</span>, window=<span class="number">5</span>, min_count=<span class="number">20</span>, workers=multiprocessing.cpu_count())</div><div class="line"></div><div class="line">    <span class="comment"># trim unneeded model memory = use(much) less RAM</span></div><div class="line">    <span class="comment"># model.init_sims(replace=True)</span></div><div class="line">    <span class="comment">#保存模型</span></div><div class="line">    model.save(outp1)</div><div class="line">    model.save_word2vec_format(outp2, binary=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>说明一下：在MyDocs这个类中，我自定义了一个逐步读取文件的方法，因为在试验中我们发现，一个4个G 左右大小的文件在一个服务器内存为64G 的服务器上是不够用的，内存消耗非常之快，所以就看了一下源码中TaggedLineDocument和LineSentence这个类的源码，发现使用 yield这个关键字能很好的解决这个问题，便有了MyDocs类，实验结果表明，效果大大提高。有兴趣的同学可以看看 yield的用法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试模型</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Doc2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="comment"># check and process input arguments</span></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    file, word = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line"></div><div class="line">    <span class="comment">#加载模型</span></div><div class="line">    docvecs = Doc2Vec.load(file).docvecs</div><div class="line">    print(docvecs.most_similar(word))</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章主要是实现Python 自然语言处理包 gensim 中用于长文本向量建模的 doc2vec算法。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=
    
    </summary>
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>word2vct算法实现</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/word2vct%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/word2vct算法实现/</id>
    <published>2017-03-21T09:50:51.000Z</published>
    <updated>2017-03-31T12:58:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章主要是实现Python 自然语言处理包 gensim 中用于词向量建模的 word2vec算法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># encoding=utf-8</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    outputFile1, outputFile2 = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line"></div><div class="line">    sentences = [</div><div class="line">        <span class="string">"I think that most of us know by now that water is essential to our survival We’ve probably also all heard doctors say that drinking roughly eight glasses a day is ideal"</span>,</div><div class="line">        <span class="string">"yoyoyo you go home now to sleep"</span>]</div><div class="line"></div><div class="line">    vocab = [s.encode(<span class="string">'utf-8'</span>).decode().split() <span class="keyword">for</span> s <span class="keyword">in</span> sentences]</div><div class="line">    <span class="comment">#建立模型</span></div><div class="line">    model = Word2Vec(sentences, size=<span class="number">100</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, workers=<span class="number">4</span>)</div><div class="line">    <span class="comment">#保存模型</span></div><div class="line">    model.save(outputFile1)</div><div class="line">    model.save_word2vec_format(outputFile2, binary=<span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试模型</span></div><div class="line"><span class="comment"># encoding='utf-8'</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    file, word = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</div><div class="line">    <span class="comment">#从磁盘文件 file 加载模型</span></div><div class="line">    model = Word2Vec.load_word2vec_format(file, binary=<span class="keyword">False</span>)</div><div class="line">    print(model.most_similar(word))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇文章主要是实现Python 自然语言处理包 gensim 中用于词向量建模的 word2vec算法。&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;l
    
    </summary>
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://JiangFeng07.github.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow 安装和卸载</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/tensorflow-%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/tensorflow-安装和卸载/</id>
    <published>2017-03-21T09:07:31.000Z</published>
    <updated>2017-03-21T11:00:54.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于-virtualenv-安装"><a href="#基于-virtualenv-安装" class="headerlink" title="基于 virtualenv 安装"></a>基于 virtualenv 安装</h2><p>安装步骤如下：</p>
<ol>
<li>打开终端（a shell）;</li>
<li><p>安装 pip（如果之前没有安装的话） 和 virtualenv :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo easy_install pip</div><div class="line">$ sudo pip install --upgrade virtualenv</div></pre></td></tr></table></figure>
</li>
<li><p>建立一个新的 virtualenv 环境 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ virtualenv --system-site-packages ~/tensorflow</div></pre></td></tr></table></figure>
</li>
<li><p>激活 virtualenv :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ cd ~/tensorflow</div><div class="line">$ source bin/activate # 如果使用 bash, sh, ksh, 或者 zsh</div><div class="line">$ source bin/activate.csh # 如果使用 csh 或者 tcsh</div><div class="line">终端发生变化:</div><div class="line">(tensorflow)$</div></pre></td></tr></table></figure>
</li>
<li><p>安装 tensorflow :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install --upgrade tensorflow # for python 2.7</div><div class="line">pip3 install --upgrade tensorflow # for python 3.n</div></pre></td></tr></table></figure>
</li>
<li><p>测试是否安装成功 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(tensorflow) $ bin python</div><div class="line">Python 3.5.2 (default, Jul 28 2016, 21:28:00)</div><div class="line">[GCC 4.2.1 Compatible Apple LLVM 7.3.0 (clang-703.0.31)] on darwin</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)</div><div class="line">&gt;&gt;&gt; sess = tf.Session()</div><div class="line">&gt;&gt;&gt; print(sess.run(hello))</div><div class="line">b&apos;Hello, TensorFlow!&apos; # 安装成功</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="tensorflow-卸载"><a href="#tensorflow-卸载" class="headerlink" title="tensorflow 卸载"></a>tensorflow 卸载</h2><ol>
<li>执行卸载很简单，直接删除目录即可：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rm -r ~/tensorflow</div></pre></td></tr></table></figure></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基于-virtualenv-安装&quot;&gt;&lt;a href=&quot;#基于-virtualenv-安装&quot; class=&quot;headerlink&quot; title=&quot;基于 virtualenv 安装&quot;&gt;&lt;/a&gt;基于 virtualenv 安装&lt;/h2&gt;&lt;p&gt;安装步骤如下：&lt;/p&gt;
&lt;o
    
    </summary>
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://JiangFeng07.github.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://JiangFeng07.github.com/2017/03/21/hello-world/"/>
    <id>http://JiangFeng07.github.com/2017/03/21/hello-world/</id>
    <published>2017-03-21T08:56:25.000Z</published>
    <updated>2017-04-01T02:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
</feed>
